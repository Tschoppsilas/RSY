{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T12:12:11.520022Z",
     "start_time": "2025-05-07T12:12:11.506346Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:14:02.576022Z",
     "start_time": "2025-05-07T12:14:02.397050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Gefilterte Datensätze wieder den Variablen zuweisen:\n",
    "output_dir = Path(\"Data/filtered_data\")\n",
    "csv_path_links = output_dir / \"links_cleaned.csv\"\n",
    "csv_path_movies = output_dir / \"movies_cleaned.csv\"\n",
    "csv_path_ratings = output_dir / \"ratings_cleaned.csv\"\n",
    "csv_path_tags = output_dir / \"tags_cleaned.csv\"\n",
    "links = pd.read_csv(csv_path_links)\n",
    "movies = pd.read_csv(csv_path_movies)\n",
    "ratings = pd.read_csv(csv_path_ratings)\n",
    "tags = pd.read_csv(csv_path_tags)"
   ],
   "id": "9b49b48ed39f612e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:14:03.733408Z",
     "start_time": "2025-05-07T12:14:03.561400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dir = Path(\"Data/Train_Test_Validate\")\n",
    "csv_path_train = output_dir / \"train_df.csv\"\n",
    "csv_path_test = output_dir / \"test_df.csv\"\n",
    "training = pd.read_csv(csv_path_train)\n",
    "test = pd.read_csv(csv_path_test)\n",
    "csv_path_test_masked = output_dir / \"test_df_masked.csv\"\n",
    "test_masked = pd.read_csv(csv_path_test_masked)"
   ],
   "id": "815501dd987d98e1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Aufgabe 2",
   "id": "dd17baaba12397f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:16:51.285285Z",
     "start_time": "2025-05-07T12:16:34.914967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_biases(df, beta_u=20, beta_i=20, iteration=10):\n",
    "    #erstellt einen Key, wenn der aufgerufene Key nicht existiert\n",
    "    b_i = defaultdict(float)\n",
    "    b_u = defaultdict(float)\n",
    "    #Globalen Durchschnitt berechnen\n",
    "    mu = df[\"rating\"].mean()\n",
    "\n",
    "    # Vorab gruppieren nach User und Movie\n",
    "    user_groups = df.groupby(\"userId\")\n",
    "    movie_groups = df.groupby(\"movieId\")\n",
    "\n",
    "    for _ in range(iteration):\n",
    "        # Update b_u\n",
    "        for user_id, group in user_groups:\n",
    "            numer = (group[\"rating\"] - mu - group[\"movieId\"].map(b_i)).sum()#Summe der Abweichung für den nutzer\n",
    "            denom = beta_u + len(group) #Filme mit weniger bewertungen sollen damit stärker reguliert werden\n",
    "            b_u[user_id] = numer / denom #berechneter user bias\n",
    "\n",
    "        # Update b_i\n",
    "        for movie_id, group in movie_groups:\n",
    "            numer = (group[\"rating\"] - mu - group[\"userId\"].map(b_u)).sum()#Summe der Abweichung für den Film\n",
    "            denom = beta_i + len(group)\n",
    "            b_i[movie_id] = numer / denom #berechneter item bias\n",
    "\n",
    "    return mu, dict(b_u), dict(b_i)\n",
    "\n",
    "mu_baseline, b_u_baseline, b_i_baseline = calculate_biases(ratings)"
   ],
   "id": "1bd76d682375a71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Vorhersagen für die nicht bewerteten Filme eines Users\n",
    "def predict(mu, b_u, b_i, user_ID, unrated_Itmes):\n",
    "    prediction = []\n",
    "    for item_ID in unrated_Itmes:\n",
    "        predicted_rating = mu + b_u[user_ID] + b_i[item_ID]\n",
    "        prediction.append((item_ID, predicted_rating))\n",
    "    prediction.sort(key=lambda x: x[1], reverse=True)\n",
    "    return prediction\n",
    "\n",
    "#Vorhersagen für Top-N Empfehlungen\n",
    "def get_top_n_reco(df,mu, b_u, b_i, user_ID, N = 20):\n",
    "    #Filtern nach welche Filme bereits von User bewertet wurden\n",
    "    rated = df[df[\"userId\"] == user_ID][\"movieId\"]\n",
    "    #Liste erstellen für alle nicht bertetetn Filme\n",
    "    unrated_prod = [item for item in df[\"movieId\"].unique() if item not in rated]\n",
    "    #Vorhersage berechnen wie der Nutzer den Film finden würde\n",
    "    top_n_pred = predict(mu, b_u, b_i,user_ID, unrated_prod)[:N]\n",
    "    print(f\"\\n Top {N} Empfehlungen für Benutzer {user_ID} sind:\")\n",
    "    for rank, (movie_id, score) in enumerate(top_n_pred, start=1):\n",
    "        movie_title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
    "        print(f\"{rank}. {movie_title} - Vorhergesagter Wert: {score:.2f}\")\n",
    "\n",
    "\n",
    "get_top_n_reco(ratings,mu_baseline, b_u_baseline, b_i_baseline, 1)\n",
    "get_top_n_reco(ratings,mu_baseline, b_u_baseline, b_i_baseline, 3)\n",
    "get_top_n_reco(ratings,mu_baseline, b_u_baseline, b_i_baseline, 7)"
   ],
   "id": "27c138856df8fc93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def random_recom(df, user_ID, mu, b_u, b_i, movies, N=20):\n",
    "    # Filme, die der User schon gesehen hat\n",
    "    rated = df[df['userId'] == user_ID]['movieId']\n",
    "    \n",
    "    # Alle anderen Filme\n",
    "    unrated_prod = [item for item in df[\"movieId\"].unique() if item not in rated.values]\n",
    "    \n",
    "    # Zufällige Auswahl\n",
    "    random_recommendations = random.sample(unrated_prod, min(N, len(unrated_prod)))\n",
    "    \n",
    "    print(f\"\\nZufällige Empfehlungen für User {user_ID} mit vorhergesagtem Score:\")\n",
    "    \n",
    "    for rank, movie_id in enumerate(random_recommendations, start=1):\n",
    "        title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
    "        \n",
    "        # Vorhersage berechnen, wenn User- oder Item-Bias fehlen, nutze 0\n",
    "        bu = b_u.get(user_ID, 0)\n",
    "        bi = b_i.get(movie_id, 0)\n",
    "        pred_score = mu + bu + bi\n",
    "        \n",
    "        print(f\"{rank}. {title} — Vorhergesagter Score: {pred_score:.2f}\")\n",
    "        \n",
    "random_recom(ratings, user_ID=1, mu=mu_baseline, b_u=b_u_baseline, b_i=b_i_baseline, movies=movies, N=20)\n",
    "random_recom(ratings, user_ID=3, mu=mu_baseline, b_u=b_u_baseline, b_i=b_i_baseline, movies=movies, N=20)\n",
    "random_recom(ratings, user_ID=7, mu=mu_baseline, b_u=b_u_baseline, b_i=b_i_baseline, movies=movies, N=20)"
   ],
   "id": "9d206bc1126c2c5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Aufgabe 3",
   "id": "787f23be49e63106"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:14:08.333040Z",
     "start_time": "2025-05-07T12:14:08.302829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#debug_TEST\n",
    "def cross_validation(dataset, parts=5, keep_frac=0.2, random_state=42):\n",
    "    user_unique = dataset[\"userId\"].unique()\n",
    "    user_shuffled = pd.Series(user_unique).sample(frac=1, random_state=random_state).values\n",
    "    user_folds = np.array_split(user_shuffled, parts)\n",
    "\n",
    "    train_sets = []\n",
    "    validation_visible_sets = []\n",
    "    validation_ground_truth_sets = []\n",
    "\n",
    "    for fold_users in user_folds:\n",
    "        is_validation = dataset[\"userId\"].isin(fold_users)\n",
    "        train_set = dataset[~is_validation].copy()\n",
    "        validation_set = dataset[is_validation].copy()\n",
    "\n",
    "        # Sichtbare Bewertungen (All-but-X%)\n",
    "        validation_visible = (\n",
    "            validation_set\n",
    "            .groupby(\"userId\", group_keys=False)\n",
    "            .apply(lambda x: x.sample(\n",
    "                frac=keep_frac if len(x) > 1 else 1.0,\n",
    "                random_state=random_state\n",
    "            ))\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # Maskierte Bewertungen = Ground Truth\n",
    "        validation_ground_truth = validation_set.merge(\n",
    "            validation_visible,\n",
    "            how=\"outer\",\n",
    "            on=[\"userId\", \"movieId\", \"rating\"],\n",
    "            indicator=True\n",
    "        )\n",
    "        validation_ground_truth = validation_ground_truth[\n",
    "            validation_ground_truth[\"_merge\"] == \"left_only\"\n",
    "        ].drop(columns=[\"_merge\"])\n",
    "\n",
    "        train_sets.append(train_set)\n",
    "        validation_visible_sets.append(validation_visible)\n",
    "        validation_ground_truth_sets.append(validation_ground_truth)\n",
    "\n",
    "    return train_sets, validation_visible_sets, validation_ground_truth_sets\n"
   ],
   "id": "97cd86553e52059c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:14:20.418581Z",
     "start_time": "2025-05-07T12:14:10.370087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Versuch\n",
    "df_train, df_val_visible, df_val_ground = cross_validation(training, parts=5, keep_frac=0.2)\n",
    "\n",
    "output_dir = Path(\"Data/Train_Test_Validate/Versuch\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for idx in range(5):\n",
    "    df_train[idx].to_csv(output_dir / f\"train_set_{idx+1}.csv\", index=False)\n",
    "    df_val_visible[idx].to_csv(output_dir / f\"validate_masked_{idx+1}.csv\", index=False)\n",
    "    df_val_ground[idx].to_csv(output_dir / f\"validate_groundtruth_{idx+1}.csv\", index=False)"
   ],
   "id": "7ae56a798aea4ff5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:17:25.080735Z",
     "start_time": "2025-05-07T12:17:24.810372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Versuch\n",
    "output_dir = Path(\"Data/Train_Test_validate/Versuch\")\n",
    "\n",
    "# Trainingssets\n",
    "train_set_1 = pd.read_csv(output_dir / \"train_set_1.csv\")\n",
    "train_set_2 = pd.read_csv(output_dir / \"train_set_2.csv\")\n",
    "train_set_3 = pd.read_csv(output_dir / \"train_set_3.csv\")\n",
    "train_set_4 = pd.read_csv(output_dir / \"train_set_4.csv\")\n",
    "train_set_5 = pd.read_csv(output_dir / \"train_set_5.csv\")\n",
    "\n",
    "# Validierungssätze (sichtbare Ratings, All-but-X%)\n",
    "validate_masked_1 = pd.read_csv(output_dir / \"validate_masked_1.csv\")\n",
    "validate_masked_2 = pd.read_csv(output_dir / \"validate_masked_2.csv\")\n",
    "validate_masked_3 = pd.read_csv(output_dir / \"validate_masked_3.csv\")\n",
    "validate_masked_4 = pd.read_csv(output_dir / \"validate_masked_4.csv\")\n",
    "validate_masked_5 = pd.read_csv(output_dir / \"validate_masked_5.csv\")\n",
    "\n",
    "# Ground Truths (maskierte Bewertungen, zum Auswerten)\n",
    "validate_groundtruth_1 = pd.read_csv(output_dir / \"validate_groundtruth_1.csv\")\n",
    "validate_groundtruth_2 = pd.read_csv(output_dir / \"validate_groundtruth_2.csv\")\n",
    "validate_groundtruth_3 = pd.read_csv(output_dir / \"validate_groundtruth_3.csv\")\n",
    "validate_groundtruth_4 = pd.read_csv(output_dir / \"validate_groundtruth_4.csv\")\n",
    "validate_groundtruth_5 = pd.read_csv(output_dir / \"validate_groundtruth_5.csv\")\n"
   ],
   "id": "201f2fa35ae15c85",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:18:28.441240Z",
     "start_time": "2025-05-07T12:18:28.409178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mean Absolute Error (MAE)\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "\n",
    "# Root Mean Square Error (RMSE)\n",
    "def root_mean_square_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "# Precision@N berechnen\n",
    "def precision_at_n(predictions, relevant_items, N=15, threshold=4.0):\n",
    "    # Filtere relevante Items\n",
    "    relevant_items = [item for item in relevant_items if item[1] >= threshold]\n",
    "    \n",
    "    # Berechne die Top-N Empfehlungen\n",
    "    top_n_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:N]\n",
    "    \n",
    "    # Berechne Precision\n",
    "    relevant_in_top_n = sum(1 for item in top_n_predictions if item[0] in [x[0] for x in relevant_items])\n",
    "    return relevant_in_top_n / N if N > 0 else 0\n",
    "\n",
    "# Recall@N berechnen\n",
    "def recall_at_n(predictions, relevant_items, N=15, threshold=4.0):\n",
    "    # Filtere relevante Items\n",
    "    relevant_items = [item for item in relevant_items if item[1] >= threshold]\n",
    "    \n",
    "    # Berechne die Top-N Empfehlungen\n",
    "    top_n_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:N]\n",
    "    \n",
    "    # Berechne Recall\n",
    "    relevant_in_top_n = sum(1 for item in top_n_predictions if item[0] in [x[0] for x in relevant_items])\n",
    "    return relevant_in_top_n / len(relevant_items) if len(relevant_items) > 0 else 0\n",
    "\n",
    "def precision_recall_at_n(predicted_list, true_list, N=15, threshold=4.0):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for uid in predicted_list:\n",
    "        if uid not in true_list:\n",
    "            continue\n",
    "\n",
    "        preds = predicted_list[uid]\n",
    "        truths = true_list[uid]\n",
    "\n",
    "        # Relevante Items im Ground Truth\n",
    "        true_relevant = set(iid for iid, rating in truths if rating >= threshold)\n",
    "        if not true_relevant:\n",
    "            continue\n",
    "\n",
    "        # Top-N vorhergesagte Items\n",
    "        top_n = sorted(preds, key=lambda x: x[1], reverse=True)[:N]\n",
    "        recommended = set(iid for iid, rating in top_n if rating >= threshold)\n",
    "\n",
    "        # Schnittmenge\n",
    "        rel_and_rec = recommended & true_relevant\n",
    "\n",
    "        precision = len(rel_and_rec) / len(recommended) if recommended else 0\n",
    "        recall = len(rel_and_rec) / len(true_relevant)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls)"
   ],
   "id": "ecbc48e975eaa5d2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Aufgabe 4",
   "id": "7870a65b775aa78a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T12:15:47.254438Z",
     "start_time": "2025-05-07T12:15:41.530360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Anpassung, da ich true und prediction am besten direkt hier berechne deshalb compute_rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def compute_rmse(mu, b_u, b_i, test_df):\n",
    "    preds = []   # Liste zur Speicherung der vorhergesagten Bewertungen\n",
    "    actuals = [] # Liste zur Speicherung der tatsächlichen Bewertungen\n",
    "    \n",
    "    # Iteration über alle Zeilen des Test-Datensatzes\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Extrahiere Nutzer-ID, Film-ID und tatsächliche Bewertung aus der aktuellen Zeile\n",
    "        u, i, true_rating = row[\"userId\"], row[\"movieId\"], row[\"rating\"]\n",
    "        \n",
    "        # Berechne die vorhergesagte Bewertung:\n",
    "        # globale Durchschnittsbewertung + Nutzer-Bias + Item-Bias\n",
    "        # Falls kein Bias vorhanden ist, verwende 0 als Standardwert\n",
    "        pred_rating = mu + b_u.get(u, 0) + b_i.get(i, 0)\n",
    "        \n",
    "        # Speichere die Vorhersage und die tatsächliche Bewertung\n",
    "        preds.append(pred_rating)\n",
    "        actuals.append(true_rating)\n",
    "    \n",
    "    # Berechne und gib die RMSE zwischen den tatsächlichen und vorhergesagten Bewertungen zurück\n",
    "    return np.sqrt(mean_squared_error(actuals, preds))"
   ],
   "id": "4311b5de77c89abd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-07T12:21:51.610719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Parameter und Ergebnis-Speicher ===\n",
    "beta_values = [1, 5, 10, 20]\n",
    "rmse_list, mae_values, precision_values, recall_values = [], [], [], []\n",
    "\n",
    "train_sets = [pd.read_csv(output_dir / f\"train_set_{i}.csv\") for i in range(1, 6)]\n",
    "validate_masked_sets = [pd.read_csv(output_dir / f\"validate_masked_{i}.csv\") for i in range(1, 6)]\n",
    "validate_groundtruth_sets = [pd.read_csv(output_dir / f\"validate_groundtruth_{i}.csv\") for i in range(1, 6)]\n",
    "\n",
    "# === Hauptschleife über alle Betas & Folds ===\n",
    "for beta_u in beta_values:\n",
    "    for beta_i in beta_values:\n",
    "        all_rmse, all_mae, all_prec, all_rec = [], [], [], []\n",
    "\n",
    "        for fold in range(5):\n",
    "            train_set = train_sets[fold]\n",
    "            val_masked = validate_masked_sets[fold]\n",
    "            val_groundtruth = validate_groundtruth_sets[fold]\n",
    "\n",
    "            mu, b_u, b_i = calculate_biases(train_set, beta_u=beta_u, beta_i=beta_i, iteration=10)\n",
    "\n",
    "            # Vorhersagen auf Groundtruth\n",
    "            predictions = [mu + b_u.get(u, 0) + b_i.get(i, 0)\n",
    "                           for u, i in zip(val_groundtruth[\"userId\"], val_groundtruth[\"movieId\"])]\n",
    "            true_ratings = val_groundtruth[\"rating\"].values\n",
    "\n",
    "            rmse = compute_rmse(mu, b_u, b_i, val_groundtruth)\n",
    "            mae = mean_absolute_error(true_ratings, predictions)\n",
    "\n",
    "            user_preds = defaultdict(list)\n",
    "            user_truths = defaultdict(list)\n",
    "\n",
    "            for u, i, true_r, pred_r in zip(val_groundtruth[\"userId\"], val_groundtruth[\"movieId\"], val_groundtruth[\"rating\"], predictions):\n",
    "                user_preds[u].append((i, pred_r))\n",
    "                user_truths[u].append((i, true_r))\n",
    "\n",
    "            precision, recall = precision_recall_at_n(user_preds, user_truths, N=15, threshold=4.0)\n",
    "\n",
    "            all_rmse.append(rmse)\n",
    "            all_mae.append(mae)\n",
    "            all_prec.append(precision)\n",
    "            all_rec.append(recall)\n",
    "\n",
    "        rmse_list.append((beta_u, beta_i, np.mean(all_rmse)))\n",
    "        mae_values.append((beta_u, beta_i, np.mean(all_mae)))\n",
    "        precision_values.append((beta_u, beta_i, np.mean(all_prec)))\n",
    "        recall_values.append((beta_u, beta_i, np.mean(all_rec)))\n",
    "\n",
    "        print(f\"β_u: {beta_u}, β_i: {beta_i}, RMSE: {np.mean(all_rmse):.4f}, MAE: {np.mean(all_mae):.4f}, \"\n",
    "              f\"Precision@N: {np.mean(all_prec):.4f}, Recall@N: {np.mean(all_rec):.4f}\")\n",
    "\n",
    "# === Heatmaps erzeugen ===\n",
    "def plot_heatmap(df, metric_name, cmap=\"viridis\"):\n",
    "    pivot = df.pivot(index=\"beta_u\", columns=\"beta_i\", values=metric_name)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".3f\", cmap=cmap)\n",
    "    plt.title(f\"{metric_name} Heatmap für verschiedene β-Werte\")\n",
    "    plt.xlabel(\"β_i\")\n",
    "    plt.ylabel(\"β_u\")\n",
    "    plt.show()\n",
    "\n",
    "df_results = pd.DataFrame(rmse_list, columns=[\"beta_u\", \"beta_i\", \"rmse\"])\n",
    "df_mae = pd.DataFrame(mae_values, columns=[\"beta_u\", \"beta_i\", \"mae\"])\n",
    "df_precision = pd.DataFrame(precision_values, columns=[\"beta_u\", \"beta_i\", \"precision\"])\n",
    "df_recall = pd.DataFrame(recall_values, columns=[\"beta_u\", \"beta_i\", \"recall\"])\n",
    "\n",
    "plot_heatmap(df_results, \"rmse\")\n",
    "plot_heatmap(df_mae, \"mae\")\n",
    "plot_heatmap(df_precision, \"precision\")\n",
    "plot_heatmap(df_recall, \"recall\")"
   ],
   "id": "b7c1b1d29d37b086",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
