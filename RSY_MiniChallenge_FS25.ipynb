{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems - Mini Challenge HS24\n",
    "\n",
    "In this minichallenge we will explore a MovieLens dataset and implement several recommender systems and evaluation methods. Subsequently we will optimize these methods and compare the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission deadline:** 24.11.2024 18:00. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines for Implementation and Submission\n",
    "- Code must be written in Python. The versions of all used packages must be given for reproducability.\n",
    "- You may respond in English or German.\n",
    "- We develop numerous algorithms ourselves. Unless explicitly stated otherwise, only the following libraries may be used in Python: numpy, matplotlib, seaborn, pandas. \n",
    "- Follow good coding practices and write modular, reusable code.\n",
    "- The submitted solution must contain all codes and the results. No code may be outsourced.\n",
    "- All pathes must be relative and just downloading your repo must be executable without modifications.\n",
    "- Only fully running code is graded. The notebook must run sequential from start to end.\n",
    "- If computation time is too long for productive prototyping and debugging work, it is recommended to reduce the dataset to a fraction of its original. However, final results should be calculated on the full dataset. \n",
    "- All plots must be fully labeled (title, axes, labels, colorbar, etc.) so that the plot can be easily understood.\n",
    "- Each plot should be accompanied by a brief discussion, which explains the plot and captures the key insights that become visible.\n",
    "- Only fully labeled plots with an accompanying discussion will be assessed.\n",
    "- The last commit in your fork of the repo before the submission deadline counts as the submission.\n",
    "- Points will be deducted if you write inconsise (Denial of service will be punished) or if I read the text that are not written for me but for the user of ChatGPT. \n",
    "- If you would like to submit and have the mini-challenge assessed, please send a short email to the subject expert (moritz.kirschmann@fhnw.ch) within 2 days after submission.\n",
    "- Please do not delete, duplicate, or move the existing cells. This leads to problems during the correction. However, you may add as many additional cells as you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - A deep exploration of the dataset (17 points)\n",
    "We will work with a subset of the MovieLens dataset. This subset is located under ``data/ml-latest-small``. Read the ``README.txt``carefully. \n",
    "Open the files. \n",
    "\n",
    "a) Describe the available data.\n",
    "\n",
    "Die Daten von MovieLens, einem Filmempfehlungsdienst, beschreiben 5-Sterne-Bewertungen von Filmen. Er enthält 100’836 Bewertungen und 3’683 Tags-Anwendungen für 9’742 Filme. Diese Daten wurden von 610 Nutzern zwischen dem 29. März 1996 und dem 24. September 2018 erstellt. Der Datensatz wurde am 26. September 2018 erstellt.\n",
    "Die Nutzer wurden nach dem Zufallsprinzip für die Aufnahme ausgewählt. Alle ausgewählten Nutzer hatten mindestens 20 Filme bewertet. Es sind keine demografischen Informationen enthalten. Jeder Nutzer wird durch eine ID repräsentiert, und es werden keine weiteren Informationen bereitgestellt.\n",
    "Die Daten sind in den Dateien «links.csv», «movies.csv», «ratings.csv» und «tags.csv» enthalten. \n",
    "Die Daten:\n",
    "•\tratings.csv: Enthält alle Bewertungen. Jede Zeile repräsentiert eine Bewertung eines Films durch einen Benutzer und hat das Format: «userId», «movieId», «rating» und «timestamp». Die Bewertungen erfolgen auf einer 5-Sterne-Skala mit Abstufungen von einem halben Stern (0,5 Sterne - 5,0 Sterne).\n",
    "•\ttags.csv: Enthält alle tags (Etikett). Jede Zeile repräsentiert ein tag, das von einem Benutzer auf einen Film angewendet wurde, und hat das Format: «userId», «movieId», «tag» und «timestamp». Tags sind vom Benutzer erstellte Metadaten zu Filmen, wie beispielsweise der Hauptdarsteller oder ein Wort das beschreibt um was es im Gilm geht (bsp. Wedding wenn im Film geheiratet wird).\n",
    "•\tmovies.csv: Enthält Filminformationen. Jede Zeile repräsentiert einen Film und hat das Format: «movieId», «title» und «genres». Die Genres sind eine durch Pipes ( | ) getrennte Liste, welche genres vom Film alles abgedeckt werden.\n",
    "•\tlinks.csv: Enthält Bezeichner zur Verknüpfung mit anderen Quellen von Filmdaten. Jede Zeile repräsentiert einen Film und hat das Format: «movieId», «imdbId» (imbdId = Internet Movie Database ID) und «tmdbId» (tmdbid = The Movie Database ID). Diese IDs helfen dabei, einen Film eindeutig auf verschiedenen Plattformen zu identifizieren. Wenn man also eine bestimmte Filminformation abrufen möchte, kann man die jeweilige ID nutzen, um den Film auf einer der Plattformen zu finden.\n",
    "\n",
    "Programmiertechnisch wird der Datensatz im Abschnitt unter dem Markdown \"a) Describe the available data\" gezeigt.\n",
    "\n",
    "\n",
    "b) Find and fix bad data (e.g. duplicates, missing values, etc.).\n",
    "\n",
    "Generate lists of\n",
    "\n",
    "c) - Top 20 movies by average rating\n",
    "\n",
    "d) - Top 20 movies by number of views\n",
    "\n",
    "e) What is the range of the ratings? \n",
    "\n",
    "f) Which genre has be rated how many times?\n",
    "\n",
    "g) How sparse is the User Rating Matrix?\n",
    "\n",
    "Plot the following:\n",
    "\n",
    "h) How many users have rated how many movies\n",
    "\n",
    "i) Which rating is given how often on average\n",
    "\n",
    "j) Which rating is given how often on average per genre\n",
    "\n",
    "k) The rating distributions of 10 random movies\n",
    "\n",
    "l) The rating distributions of 3 movies that you have watched\n",
    "\n",
    "m) How many users give which average rating\n",
    "\n",
    "n) How often a movie was rated as a function of average rating\n",
    "\n",
    "o) A heatmap of the User Item Matrix\n",
    "\n",
    "p) A heatmap of the User Item Matrix for the 100 most rated movies for the 50 users with most ratings\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "#Damit die Liste im Output besser aussieht brauche ich pprint\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Datensätze einlesen\n",
    "output_dir = Path(\"Data\\ml-latest-small\")\n",
    "csv_path_links = output_dir / \"links.csv\"\n",
    "csv_path_movies = output_dir / \"movies.csv\"\n",
    "csv_path_ratings = output_dir / \"ratings.csv\"\n",
    "csv_path_tags = output_dir / \"tags.csv\"\n",
    "links_raw = pd.read_csv(csv_path_links)\n",
    "movies_raw = pd.read_csv(csv_path_movies)\n",
    "ratings_raw = pd.read_csv(csv_path_ratings)\n",
    "tags_raw = pd.read_csv(csv_path_tags)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## a) Describe the available data."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Aufgabe A\n",
    "def data_describe(df, name):\n",
    "    print(f\"{name} Datensatz\")\n",
    "    print(\"\\n Info\")\n",
    "    pprint.pprint(df.info())\n",
    "    print(\"\\n Head\")\n",
    "    pprint.pprint(df.head())\n",
    "\n",
    "data_describe(links_raw, \"links\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_describe(movies_raw, \"movies\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_describe(ratings_raw, \"ratings\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_describe(tags_raw, \"tags\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## b) Find and fix bad data (e.g. duplicates, missing values, etc.)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Aufgabe B\n",
    "# Pfade der Datensätze um sicherzugehen, dass ich die nehme, die noch unberührt sind\n",
    "files = {\n",
    "    \"links\": \"Data/ml-latest-small/links.csv\",\n",
    "    \"movies\": \"Data/ml-latest-small/movies.csv\",\n",
    "    \"ratings\": \"Data/ml-latest-small/ratings.csv\",\n",
    "    \"tags\": \"Data/ml-latest-small/tags.csv\",\n",
    "}\n",
    "\n",
    "# Funktion zur Bereinigung und Standardisierung von CSV-Daten\n",
    "def clean_dataframe(df):\n",
    "    # Entfernen von unnötigen Anführungszeichen, die den gesamten Wert umschliessen, da mir auffiel, dass es im Datensatz Movies dieses Problem gab\n",
    "    def clean_string(x):\n",
    "        if isinstance(x, str):\n",
    "            # Entfernen von führenden und nachfolgenden Anführungszeichen\n",
    "            x = x.strip(\"'\\\"\")\n",
    "        return x\n",
    "\n",
    "    df = df.map(clean_string)\n",
    "    \n",
    "    # mögliche \"<unset>\" durch NaN ersetzen\n",
    "    df = df.replace(\"<unset>\", np.nan)\n",
    "    \n",
    "    # Überprüfen und Anpassen des Datentyps\n",
    "    for column in df.columns:\n",
    "        # Versuchen, den Datentyp zu inferieren und zu casten, falls der Datentyp nicht konsistent ist\n",
    "        if df[column].dtype == 'object':\n",
    "            # Überprüfen, ob die Spalte nur numerische Werte enthält\n",
    "            try:\n",
    "                df[column] = pd.to_numeric(df[column], errors='raise')\n",
    "            except ValueError:\n",
    "                pass  # Wenn es nicht konvertierbar ist, behalten wir den ursprünglichen Datentyp bei\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Lade Daten in DataFrames und stelle sicher, dass die erste Zeile als Spaltennamen verwendet wird\n",
    "dfs = {}\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    \n",
    "    # Setze die erste Zeile als Spaltennamen\n",
    "    df.columns = df.iloc[0]\n",
    "    \n",
    "    # Entferne die erste Zeile, da sie jetzt die Spaltenüberschriften sind\n",
    "    df = df.drop(0, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    dfs[name] = df\n",
    "\n",
    "# Anwenden der Reinigung auf alle DataFrames\n",
    "dfs_cleaned = {name: clean_dataframe(df) for name, df in dfs.items()}\n",
    "\n",
    "# Zielordner definieren um die neuen DF von den alten getrennt zu speichern\n",
    "output_dir = \"Data/filtered_data\"\n",
    "\n",
    "# Sicherstellen, dass der Zielordner existiert\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for name, df in dfs_cleaned.items():\n",
    "    # Berechnen der Anzahl der Duplikate und NA aus den gefilterten Daten um zu zeigen, dass sie gut gefiltert wurden\n",
    "    duplicates_count = df.duplicated().sum()\n",
    "    na_count = df.isna().sum()\n",
    "    # Ausgabe der Anzahl der Duplikate\n",
    "    print(f\"Anzahl der Duplikate im {name}-Datensatz: {duplicates_count}\\n\")\n",
    "    # Ausgabe der Anzahl der NA\n",
    "    print(f\"Anzahl der NA im {name}-Datensatz: {na_count}\\n\")\n",
    "    \n",
    "    # Speichern der bereinigten DataFrames als CSV-Dateien\n",
    "    df.to_csv(os.path.join(output_dir, f\"{name}_cleaned.csv\"), index=False)\n",
    "\n",
    "print(\"Bereinigte Daten wurden gespeichert.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Gefilterte Datensätze wieder den Variablen zuweisen:\n",
    "output_dir = Path(\"Data/filtered_data\")\n",
    "csv_path_links = output_dir / \"links_cleaned.csv\"\n",
    "csv_path_movies = output_dir / \"movies_cleaned.csv\"\n",
    "csv_path_ratings = output_dir / \"ratings_cleaned.csv\"\n",
    "csv_path_tags = output_dir / \"tags_cleaned.csv\"\n",
    "links = pd.read_csv(csv_path_links)\n",
    "movies = pd.read_csv(csv_path_movies)\n",
    "ratings = pd.read_csv(csv_path_ratings)\n",
    "tags = pd.read_csv(csv_path_tags)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## c) Generate a lis of Top 20 movies by average rating"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#gruppiert die Filme und berechnet den Bewertungsdurchschnitt. Zusätzlich, nehme ich nur die höchsten 20 und wandle es zu einem DF um, damit ich es mergen kann\n",
    "top_20_movies = ratings.groupby(\"movieId\")[\"rating\"].mean().sort_values(ascending=False).head(20).reset_index()\n",
    "\n",
    "liste_top_20 = list(top_20_movies.merge(movies[[\"movieId\", \"title\"]], on=\"movieId\", how=\"left\")[\"title\"])\n",
    "pprint.pprint(liste_top_20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## d) Generate a list of Top 20 movies by number of views\n",
    "Ich gehe hier davon aus, dass ein view einer Bewertung entspricht, da ein Film für eine Bewertung zumindest einmal gesehen werden muss."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#gruppiert die Filme und summiert die ANzahl Bewertungen. Zusätzlich, nehme ich nur die höchsten 20 und wandle es zu einem DF um, damit ich es mergen kann\n",
    "top_20_movies_by_view = ratings.groupby(\"movieId\")[\"rating\"].count().sort_values(ascending=False).head(20).reset_index()\n",
    "\n",
    "liste_top_20_by_view = list(top_20_movies_by_view.merge(movies[[\"movieId\", \"title\"]], on=\"movieId\", how=\"left\")[\"title\"])\n",
    "pprint.pprint(liste_top_20_by_view)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## e) What is the range of the ratings?"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "list_of_ratings = ratings[\"rating\"].drop_duplicates().sort_values(ascending=False).tolist()\n",
    "print(f\"Die Spannweite der Bewertungen für die Filme liegt zwischen: {list_of_ratings[-1]} bis {list_of_ratings[0]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## f) Which genre has be rated how many times?"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#genres aus movies in ratings datensatz einbauen\n",
    "ratings_mit_gernes = ratings.merge(movies[[\"movieId\", \"genres\"]], on=\"movieId\", how=\"left\")\n",
    "\n",
    "# Die Genre sind teilweise mit | getrennt, was sich, wenn es nicht aufgesplittet wird, nicht sauber zählen lässt, deshalb muss es hier aufgesplittet werden\n",
    "ratings_mit_gernes_exploded = ratings_mit_gernes.assign(genre=ratings_mit_gernes[\"genres\"].str.split(\"|\")).explode(\"genre\")\n",
    "\n",
    "#Anzahl der Bewertungen pro Genre zählen\n",
    "genre_counts = ratings_mit_gernes_exploded[\"genre\"].value_counts().reset_index(name=\"count\")\n",
    "\n",
    "pprint.pprint(genre_counts)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## g) How sparse is the User Rating Matrix?"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Anzahl der eindeutigen Benutzer und Filme\n",
    "num_users = ratings[\"userId\"].nunique()\n",
    "num_movies = ratings[\"movieId\"].nunique()\n",
    "\n",
    "# Anzahl der vorhandenen Bewertungen\n",
    "num_ratings = len(ratings)\n",
    "\n",
    "# Gesamtanzahl der möglichen Bewertungen\n",
    "total_mgl_ratings = num_users * num_movies\n",
    "\n",
    "\n",
    "# Berechnung der spärlichkeit\n",
    "spärlichkeit = 1 - (num_ratings / total_mgl_ratings)\n",
    "\n",
    "print(f\"Es fehlen rund {round(spärlichkeit,4) *100}% aller möglichen Bewertungen\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## h) How many users have rated how many movies"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ratings_per_user = ratings.groupby(\"userId\")[\"rating\"].count().sort_values(ascending=False).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(ratings_per_user[\"rating\"], bins=50, label=\"Anzahl der Nutzer\")\n",
    "plt.xlabel(\"Anzahl bewerteter Filme pro Nutzer\")\n",
    "plt.ylabel(\"Anzahl Nutzer\")\n",
    "plt.title(\"Verteilung der Bewertungen pro Nutzer\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## i) Which rating is given how often on average"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ratings_avg_per_user = ratings.groupby(\"rating\")['movieId'].count() / num_users\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=ratings_avg_per_user.index, y=ratings_avg_per_user.values)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Durchschnittliche Anzahl pro Nutzer\")\n",
    "plt.title(\"Durchschnittliche Häufigkeit jeder Bewertung pro Nutzer\")\n",
    "\n",
    "# Werte über die Balken schreiben (i = index pos auf x achse, v = value pos auf y achse)\n",
    "for i, v in enumerate(ratings_avg_per_user.values):\n",
    "    plt.text(i, v + 0.5, f\"{v:.2f}\", ha='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## j) Which rating is given how often on average per genre"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#code aus aufgabe f\n",
    "#ratings_mit_gernes = ratings.merge(movies[[\"movieId\", \"genres\"]], on=\"movieId\", how=\"left\")\n",
    "#ratings_mit_gernes_exploded = ratings_mit_gernes.assign(genre=ratings_mit_gernes[\"genres\"].str.split(\"|\")).explode(\"genre\")\n",
    "\n",
    "genre_avg_ratings = ratings_mit_gernes_exploded.groupby([\"genre\", \"rating\"])[\"userId\"].count() / num_users\n",
    "\n",
    "# Umwandlung für den Plot\n",
    "genre_avg_ratings = genre_avg_ratings.reset_index(name=\"avg_rating\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for genre in genre_avg_ratings['genre'].unique():\n",
    "    genre_data = genre_avg_ratings[genre_avg_ratings['genre'] == genre]\n",
    "    plt.plot(genre_data['rating'], genre_data['avg_rating'], label=genre)\n",
    "\n",
    "\n",
    "plt.title('Durchschnittliche Bewertungen pro Genre')\n",
    "plt.xlabel('Bewertung')\n",
    "plt.ylabel('Durchschnittliche Bewertung')\n",
    "plt.legend(title=\"Genre\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## k) The rating distributions of 10 random movies"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_movies = random.sample(ratings_mit_gernes_exploded['movieId'].unique().tolist(), 10)\n",
    "\n",
    "# Erstelle Plots mit mehreren Subplots\n",
    "fig, axes = plt.subplots(5, 2, figsize=(12, 20))  # 5 Zeilen und 2 Spalten für 10 Filme\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Erstellung für jeden zufällig ausgewählten Film ein Histogramm\n",
    "for i, movie_id in enumerate(random_movies):\n",
    "    movie_ratings = ratings_mit_gernes_exploded[ratings_mit_gernes_exploded['movieId'] == movie_id]['rating']\n",
    "    \n",
    "    # Histogramm für die Bewertung jedes Films erstellen\n",
    "    axes[i].hist(movie_ratings, bins = 10, edgecolor='black')\n",
    "    axes[i].set_title(f'Bewertungsverteilung für Film {movie_id}')\n",
    "    axes[i].set_xlabel('Bewertung')\n",
    "    axes[i].set_ylabel('Anzahl der Bewertungen')\n",
    "    axes[i].set_xticks(np.arange(0, 5, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## l) The rating distributions of 3 movies that you have watched"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "watched_movie_ids = [1101, 93510, 108156]  # Ersetze dies mit den echten movieIds\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))  # 3 Zeilen für 3 Filme\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Erstelle für jeden Film ein Histogramm der Bewertungen\n",
    "for i, movie_id in enumerate(watched_movie_ids):\n",
    "    movie_ratings = ratings_mit_gernes_exploded[ratings_mit_gernes_exploded['movieId'] == movie_id]['rating']\n",
    "    \n",
    "    # Hole den Titel des Films aus dem DataFrame (erste Übereinstimmung)\n",
    "    movie_title = movies.loc[movies['movieId'] == movie_id]['title'].iloc[0]\n",
    "    \n",
    "    axes[i].hist(movie_ratings, bins=10, edgecolor='black')\n",
    "    axes[i].set_title(f'Bewertungsverteilung für Film {movie_title}')\n",
    "    axes[i].set_xlabel('Bewertung')\n",
    "    axes[i].set_ylabel('Anzahl der Bewertungen')\n",
    "    axes[i].set_xticks(np.arange(0, 5.5, 0.5))\n",
    "\n",
    "# Layout optimieren\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## m) How many users give which average rating"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Berechnung der Anzahl der einzigartigen Nutzer für jede Bewertung\n",
    "avg_rating_sum_user = ratings.groupby(\"rating\")['userId'].count().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=avg_rating_sum_user['rating'], y=avg_rating_sum_user['userId'])\n",
    "\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"Anzahl der Nutzer, die diese Bewertung abgegeben haben\")\n",
    "plt.title(\"Anzahl der Nutzer, die jede Bewertung abgegeben haben\")\n",
    "\n",
    "# Werte über die Balken schreiben (i = index pos auf x Achse, v = value pos auf y Achse)\n",
    "for i, v in enumerate(avg_rating_sum_user['userId']):\n",
    "    plt.text(i, v + 0.5, f\"{v:.0f}\", ha='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## n) How often a movie was rated as a function of average rating"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "movie_rating_statistic = ratings.groupby(\"movieId\").agg(avg_rating = (\"rating\", \"mean\"), rating_count=(\"rating\", \"count\")).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x=movie_rating_statistic[\"avg_rating\"], y=movie_rating_statistic[\"rating_count\"], alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Durchschnittliche Bewertung\")\n",
    "plt.ylabel(\"Anzahl der Bewertungen\")\n",
    "plt.title(\"Anzahl der Bewertungen als Funktion der Durchschnittsbewertung\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## o) A heatmap of the User Item Matrix"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# User-Item-Matrix erstellen\n",
    "user_item_matrix = ratings.pivot(index=\"userId\", columns=\"movieId\", values=\"rating\")\n",
    "\n",
    "# Fehlende Werte mit 0 ersetzen\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(user_item_matrix, cmap=\"coolwarm\", xticklabels=False, yticklabels=False)\n",
    "\n",
    "plt.title(\"Heatmap der User-Item-Matrix\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## p) A heatmap of the User Item Matrix for the 100 most rated movies for the 50 users with most ratings"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 50 aktivste Nutzer (mit den meisten Bewertungen) ermitteln\n",
    "top_users = ratings['userId'].value_counts().head(50).index\n",
    "\n",
    "# 100 meistbewertete Filme ermitteln\n",
    "top_movies = ratings['movieId'].value_counts().head(100).index\n",
    "\n",
    "# User-Item-Matrix nur für diese Nutzer & Filme erstellen\n",
    "filtered_ratings = ratings[(ratings['userId'].isin(top_users)) & (ratings['movieId'].isin(top_movies))]\n",
    "user_item_matrix = filtered_ratings.pivot(index=\"userId\", columns=\"movieId\", values=\"rating\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(user_item_matrix, cmap=\"coolwarm\", linewidths=0.5, linecolor=\"gray\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.title(\"Heatmap der User-Item-Matrix (Top 50 Nutzer, Top 100 Filme)\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Building a baseline RS (7 points)\n",
    "In this exercise we will build a baseline RS and functions to calculate fundamental performance metrics. \n",
    "\n",
    "Build the following baseline RS to predict Top-N (default N=20):\n",
    "1. In reference to the book *Collaborative Filtering Recommender Systems by Michael D. Ekstrand, John T. Riedl and Joseph A. Konstan* (p. 91ff) implement the baseline predictor $$ b_{u,i}= \\mu +b_u +b_i $$ with the regularized user and item average offsets: $$ b_u = \\frac{1}{|I_u| + \\beta_u} \\sum_{i \\in I_u} (r_{u,i} - \\mu) $$ and $$ b_i = \\frac{1}{|U_i| + \\beta_i} \\sum_{u \\in U_i} (r_{u,i} - b_u - \\mu) . $$ Build a recommender system upon this baseline predictor. Set the default damping factors $\\beta_u$ and $\\beta_i$ both to 20.\n",
    "2. Build a RS that recommends based on *random* recommendations.  \n",
    "\n",
    "Output the recommendations for three example users (Ids 1, 3 and 7) and the default parameters. Give the titles of the recommended movies and their predicted scores not just their Ids."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Code zur Berechnung von\n",
    "  $$ b_u = \\frac{1}{|I_u| + \\beta_u} \\sum_{i \\in I_u} (r_{u,i} - \\mu) $$ und $$ b_i = \\frac{1}{|U_i| + \\beta_i} \\sum_{u \\in U_i} (r_{u,i} - b_u - \\mu) . $$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def calculate_biases(df, beta_u=20, beta_i = 20, iteration=10):\n",
    "    b_i = dict()\n",
    "    b_u = dict()\n",
    "    # Setzt alle Biases auf 0 und iteriert über alle einzigartigen movieId, da sie meist mehrfach bewertet wurden\n",
    "    for movie_id in df[\"movieId\"].unique():\n",
    "        b_i[movie_id] = 0.0\n",
    "\n",
    "    for user_id in df[\"userId\"].unique():\n",
    "        b_u[user_id] = 0.0\n",
    "        \n",
    "    #Mu ist die Durchschnittsbewertung im ganzen System\n",
    "    mu = df[\"rating\"].mean()\n",
    "\n",
    "    # Iteration für Regularisierung\n",
    "    for _ in range(iteration):\n",
    "        # Update b_u\n",
    "        for user_id in df[\"userId\"].unique():\n",
    "            # Holen der Bewertungen dieses Benutzers\n",
    "            user_ratings = df[df[\"userId\"] == user_id]\n",
    "            # Berechne den Zähler für b_u (Summe der Abweichungen der Bewertungen des Benutzers im vergleich zur Duchschnittbewertung im ganzen System und Item-Bias)\n",
    "            zähler = ((user_ratings[\"rating\"] - mu - user_ratings[\"movieId\"].map(b_i)).sum())\n",
    "            # Berechne den Nenner für b_u (Anzahl der Bewertungen des Benutzers + Regularisierungsfaktor beta)\n",
    "            nenner = beta_u + len(user_ratings)\n",
    "            b_u[user_id] = zähler / nenner\n",
    "\n",
    "        # Update b_i\n",
    "        for movie_id in df[\"movieId\"].unique():\n",
    "            movie_ratings = df[df[\"movieId\"] == movie_id]\n",
    "            # Berechne den Zähler für b_i (Summe der Abweichungen der Bewertungen des Films im vergleich zur Duchschnittbewertung im ganzen Systemund User-Bias)\n",
    "            zähler = ((movie_ratings[\"rating\"] - mu - movie_ratings[\"userId\"].map(b_u)).sum())\n",
    "            # Berechne den Nenner für b_i (Anzahl der Bewertungen des Films + Regularisierungsfaktor beta)\n",
    "            nenner = beta_i + len(movie_ratings)\n",
    "            b_i[movie_id] = zähler / nenner\n",
    "\n",
    "    return mu, b_u, b_i\n",
    "\n",
    "\n",
    "mu, b_u, b_i = calculate_biases(ratings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_all_biases_to_csv(mu, b_u, b_i, filename='all_biases.csv'):\n",
    "\n",
    "    # Erstelle DataFrames für die Biases\n",
    "    bu_df = pd.DataFrame(list(b_u.items()), columns=['userId', 'user_bias'])\n",
    "    bi_df = pd.DataFrame(list(b_i.items()), columns=['movieId', 'item_bias'])\n",
    "    \n",
    "    # Füge mu als Spalte hinzu\n",
    "    bu_df['mu'] = mu\n",
    "    bi_df['mu'] = mu\n",
    "    \n",
    "    # Speichere in einer Datei (optional können Sie auch separate Dateien bevorzugen)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f\"Global average (mu): {mu}\\n\\n\")\n",
    "        f.write(\"User Biases:\\n\")\n",
    "        bu_df.to_csv(f, index=False)\n",
    "        f.write(\"\\n\\nItem Biases:\\n\")\n",
    "        bi_df.to_csv(f, index=False)\n",
    "\n",
    "# Aufruf:\n",
    "save_all_biases_to_csv(mu, b_u, b_i)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_all_biases_from_csv(filename='all_biases.csv'):\n",
    "    # Ganze Datei einlesen\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # 1. Globalen Durchschnitt (mu) extrahieren\n",
    "    mu = float(lines[0].strip().split(\":\")[1])\n",
    "\n",
    "    # 2. Finde Startindexe für die Tabellen\n",
    "    user_bias_start = lines.index(\"User Biases:\\n\") + 1\n",
    "    item_bias_start = lines.index(\"Item Biases:\\n\")\n",
    "\n",
    "    # 3. Extrahiere die Textblöcke für beide DataFrames\n",
    "    user_bias_lines = lines[user_bias_start:item_bias_start - 1]\n",
    "    item_bias_lines = lines[item_bias_start + 1:]\n",
    "\n",
    "    # 4. In DataFrames umwandeln\n",
    "    from io import StringIO\n",
    "    bu_df = pd.read_csv(StringIO(\"\".join(user_bias_lines)))\n",
    "    bi_df = pd.read_csv(StringIO(\"\".join(item_bias_lines)))\n",
    "\n",
    "    # 5. IDs in int umwandeln\n",
    "    bu_df['userId'] = bu_df['userId'].astype(int)\n",
    "    bi_df['movieId'] = bi_df['movieId'].astype(int)\n",
    "\n",
    "    # 6. Dictionarys erstellen\n",
    "    b_u = dict(zip(bu_df['userId'], bu_df['user_bias']))\n",
    "    b_i = dict(zip(bi_df['movieId'], bi_df['item_bias']))\n",
    "\n",
    "    return mu, b_u, b_i\n",
    "mu, b_u, b_i = load_all_biases_from_csv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Berechnung der Top-N Recommendations für die User 1,3,7\n",
    "\n",
    "Basierend auf ihren Berertungen"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Vorhersagen für die nicht bewerteten Filme eines Users\n",
    "def predict(mu, b_u, b_i, user_ID, unrated_Itmes):\n",
    "    prediction = []\n",
    "    for item_ID in unrated_Itmes:\n",
    "        predicted_rating = mu + b_u[user_ID] + b_i[item_ID]\n",
    "        prediction.append((item_ID, predicted_rating))\n",
    "    prediction.sort(key=lambda x: x[1], reverse=True)\n",
    "    return prediction\n",
    "\n",
    "#Vorhersagen für Top-N Empfehlungen\n",
    "def get_top_n_reco(df,mu, b_u, b_i, user_ID, N = 20):\n",
    "    #Filtern nach welche Filme bereits von User bewertet wurden\n",
    "    uri = df[df[\"userId\"] == user_ID][\"movieId\"]\n",
    "    #Liste erstellen für alle nicht bertetetn Filme\n",
    "    unrated_prod = [item for item in df[\"movieId\"].unique() if item not in uri]\n",
    "    #Vorhersage berechnen wie der Nutzer den Film finden würde\n",
    "    top_n_pred = predict(mu, b_u, b_i,user_ID, unrated_prod)[:N]\n",
    "    print(f\"\\n Top {N} Empfehlungen für Benutzer {user_ID} sind:\")\n",
    "    for rank, (movie_id, score) in enumerate(top_n_pred, start=1):\n",
    "        movie_title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
    "        print(f\"{rank}. {movie_title} - Vorhergesagter Wert: {score:.2f}\")\n",
    "\n",
    "\n",
    "get_top_n_reco(ratings,mu, b_u, b_i, 1)\n",
    "get_top_n_reco(ratings,mu, b_u, b_i, 3)\n",
    "get_top_n_reco(ratings,mu, b_u, b_i, 7)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Zufällige Top-N Recommendations für die User 1,3,7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def random_recom(df, user_ID, N=20):\n",
    "    uri = df[df['userId'] == user_ID]['movieId']\n",
    "    unrated_prod = [item for item in df[\"movieId\"].unique() if item not in uri]\n",
    "    random_recommendations = random.sample(unrated_prod, min(N, len(unrated_prod)))\n",
    "\n",
    "    print(f\"\\n Zufällige Empfehlungen für User {user_ID}:\")\n",
    "    for rank, movie_id in enumerate(random_recommendations, start=1):\n",
    "        movie_title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
    "        print(f\"{rank}.  {movie_title}\")\n",
    "\n",
    "random_recom(ratings, 1)\n",
    "random_recom(ratings, 3)\n",
    "random_recom(ratings, 7)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Evaluation methods (12 points)\n",
    "Split the data into train/validation set and a separate test set. This test set shall contain the first 20% of the users and shall not be used at all before exercise 10. With the remaining 80% do the following: \n",
    "Implement a function to partition your dataset for an offline evaluation based on holding out of random users with 5x cross validation with a 80/20 train/validation split. Within the validation set implement a masking with *all but n* approach. \n",
    "See page 2942 of https://jmlr.csail.mit.edu/papers/volume10/gunawardana09a/gunawardana09a.pdf for details on this approach. \n",
    "\n",
    "Choose the number of masked items n reasonably and explain your considerations.\n",
    "\n",
    "Implement functions to calculate the following metrics:\n",
    "- *Mean Absolute Error (MAE)* \n",
    "- *Root Mean Square Error (RMSE)*\n",
    "- *Precision@N* with default $N=15$ and relevance threshold 4.0 stars.\n",
    "- *Recall@N* with default $N=15$ and relevance threshold 4.0 stars.\n",
    "\n",
    "Explain each of these. How does the relevance threshold influence the metrics? How would you choose this parameter?\n",
    "\n",
    "Note: For the last two metrics use the definitions from https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54 with one exception: In case of the denominator being zero, set the metric to 0. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Datenaufteilung 20% = Test Datensatz und 80% = Trainings und Validierungsdatensatz"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def split_dataset(dataset, Test_procent=0.2):\n",
    "    user_unique = dataset[\"userId\"].unique()\n",
    "    \n",
    "    num_test_users = int(len(user_unique) * Test_procent)\n",
    "    test_users = user_unique[:num_test_users]\n",
    "    \n",
    "    #Test DF erstellen\n",
    "    df_test = dataset[dataset[\"userId\"].isin(test_users)]\n",
    "    \n",
    "    #Trainings DF estellen\n",
    "    df_train = dataset[~dataset[\"userId\"].isin(test_users)]\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = split_dataset(ratings)\n",
    "\n",
    "#in csv abspeichern\n",
    "output_dir = Path(\"Data/Train_Test_Validate\")\n",
    "df_test.to_csv(os.path.join(output_dir, f\"test_df.csv\"), index=False)\n",
    "df_train.to_csv(os.path.join(output_dir, f\"train_df.csv\"), index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_dir = Path(\"Data/Train_Test_Validate\")\n",
    "csv_path_train = output_dir / \"train_df.csv\"\n",
    "csv_path_test = output_dir / \"test_df.csv\"\n",
    "training = pd.read_csv(csv_path_train)\n",
    "test = pd.read_csv(csv_path_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Datensätze zu Variablen zuweisen"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Um herauszufinden wieviel Werte ich im Test_df_masked verstecken darf, schaue ich wieviele Bewertungen im Test_df sind."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_counts = test.groupby('userId').size()\n",
    "\n",
    "print(user_counts.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Anschliessend maskiere ich den Test_df hier"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mask_test_all_but_percent(test_df, user_col=\"userId\", rating_col=\"rating\", percent_keep=0.3, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    masked_list = []\n",
    "\n",
    "    for user_id in test_df[user_col].unique():\n",
    "        user_data = test_df[test_df[user_col] == user_id]\n",
    "\n",
    "        if len(user_data) > 1:  # Nur maskieren, wenn der Nutzer mehr als eine Bewertung hat\n",
    "            n_keep = int(len(user_data) * percent_keep)  # Anzahl der Bewertungen, die behalten werden sollen (prozentual)\n",
    "            keep = user_data.sample(n=n_keep, random_state=random_seed)  # Zufällige Auswahl der Bewertungen\n",
    "            mask = user_data.drop(keep.index).copy()  # Die Bewertungen, die nicht behalten werden\n",
    "            mask[rating_col] = np.nan  # Setze Rating auf NaN für die maskierten Bewertungen\n",
    "            user_masked = pd.concat([keep, mask])  # Kombiniere behaltene und maskierte Bewertungen\n",
    "        else:\n",
    "            user_masked = user_data  # Keine Maskierung, wenn nur eine Bewertung vorhanden ist\n",
    "\n",
    "        masked_list.append(user_masked)\n",
    "\n",
    "    test_masked = pd.concat(masked_list).reset_index(drop=True)\n",
    "    return test_masked\n",
    "\n",
    "# Test mit einer beispielhaften DataFrame\n",
    "df_test_masked = mask_test_all_but_percent(test, percent_keep=0.3)\n",
    "\n",
    "# In CSV abspeichern\n",
    "output_dir = Path(\"Data/Train_Test_Validate\")\n",
    "df_test_masked.to_csv(os.path.join(output_dir, f\"test_df_masked.csv\"), index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_dir = Path(\"Data/Train_Test_Validate\")\n",
    "csv_path_train = output_dir / \"train_df.csv\"\n",
    "csv_path_test = output_dir / \"test_df.csv\"\n",
    "training = pd.read_csv(csv_path_train)\n",
    "test = pd.read_csv(csv_path_test)\n",
    "csv_path_test_masked = output_dir / \"test_df_masked.csv\"\n",
    "test_masked = pd.read_csv(csv_path_test_masked)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cross Validation\n",
    "### Mein Vorgehen\n",
    "Ich habe zuerst den Trainingsdatensatz nach User gruppiert um dann die wichtigsten Werte auszugeben. Beispielsweise ist so zu erkennen, dass jeder Nutzer aus dem Trainings Datensatz im Durchschnitt 167.44 Bewertungen abgegeben hat. Die half mir mein validation Wert (all-but-n) Wert zu definieren. Ich habe in der Literatur, der n Wert darf nicht in der nähe von 20 sein, da ein user lediglich 20 Filme bewertet hat. Damit ich auch dort eine zutreffende Aussage machen kann, wählte ich den Wert n=10, da ich dann trotzdem die hälfte kaschiere."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_counts = training.groupby('userId').size()\n",
    "\n",
    "print(user_counts.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cross_validation(dataset, parts=5, n_keep=10, random_state=42):\n",
    "    # Shuffle users deterministisch mit pandas\n",
    "    user_unique = dataset[\"userId\"].unique()\n",
    "    user_shuffled = pd.Series(user_unique).sample(frac=1, random_state=random_state).values\n",
    "    \n",
    "    # Aufteilen der User in Folds\n",
    "    user_folds = np.array_split(user_shuffled, parts)\n",
    "    \n",
    "    train_sets = []\n",
    "    validation_sets = []\n",
    "\n",
    "    for fold_users in user_folds:\n",
    "        # Train/Validation-Split\n",
    "        train_mask = ~dataset['userId'].isin(fold_users)\n",
    "        train_set = dataset[train_mask].copy()  # Vermeide SettingWithCopyWarning\n",
    "        \n",
    "        validation_set = dataset[~train_mask].copy()\n",
    "        \n",
    "        # All-But-N-Masking mit groupby + sample\n",
    "        validation_masked = (\n",
    "            validation_set\n",
    "            .groupby('userId', group_keys=False)\n",
    "            .apply(lambda x: x.sample(n=min(n_keep, len(x)), random_state=random_state))\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        \n",
    "        # Entferne Validierungs-Items aus dem Trainingsset für die gleichen User\n",
    "        movies_to_remove = validation_set['movieId'].unique()\n",
    "        train_set_cleaned = train_set[\n",
    "            ~((train_set['userId'].isin(fold_users)) & \n",
    "            ~(train_set['movieId'].isin(movies_to_remove)))\n",
    "        ].copy()\n",
    "        \n",
    "        train_sets.append(train_set_cleaned)\n",
    "        validation_sets.append(validation_masked)\n",
    "\n",
    "    return train_sets, validation_sets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train, df_validate = cross_validation(training, parts=5, n_keep=10)\n",
    "\n",
    "\n",
    "output_dir = Path(\"Data/Train_Test_Validate\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for idx in range(5):\n",
    "    df_train[idx].to_csv(output_dir / f\"train_set_{idx+1}.csv\", index=False)\n",
    "    df_validate[idx].to_csv(output_dir / f\"validate_masked_{idx+1}.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MAE\n",
    "MAE gibt an, wie viel im Durchschnitt die Vorhersagen von den tatsächlichen Bewertungen abweichen. Ein kleiner MAE bedeutet, dass das Modell sehr genau ist. Ein hoher MAE zeigt, dass das Modell systematisch ungenaue Vorhersagen liefert. Der Schwellenwert hat in der Berechnung des MAE keinen direkten Einfluss, da MAE auf allen Bewertungen basiert, nicht nur auf den relevanten."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Mean Absolute Error (MAE)\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## RMSE\n",
    "RMSE ist ähnlich wie MAE, aber anstelle der absoluten Differenz wird das Quadrat der Differenz verwendet. Das Quadrat der Differenzen betont grössere Fehler stärker und macht RMSE empfindlicher gegenüber grossen Ausreissern. Wie bei MAE hat der Relevanz-Schwellenwert keinen direkten Einfluss auf RMSE. RMSE betrachtet alle Bewertungen und misst die durchschnittliche quadratische Abweichung, sodass alle Fehler gleich gewichtet werden."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Alles aus Aufgabe 3\n",
    "# Root Mean Square Error (RMSE)\n",
    "def root_mean_square_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Unterschiede und Zusammenspiel\n",
    "\n",
    "Precision und Recall sind zwei Seiten derselben Medaille und stehen oft in einem Trade-off-Verhältnis.\n",
    "\n",
    "**Precision** fokussiert sich darauf, wie genau die Empfehlungen sind, indem sie die Qualität der Top-N Empfehlungen bewertet. Beispielsweise hat man zwei Klassen, die man auf zwei Seiten aufteilen will. Precision betrachtet nur eine Seite und berechnet die Präzision. (Eselsbrücke: Preci**SI**on looks at elements on one **SI**de). Ein Modell mit hoher Precision hat wenige falsche Positive, was bedeutet, dass die meisten empfohlenen Items tatsächlich relevant sind.\n",
    "\n",
    "**Recall** hingegen konzentriert sich darauf, wie vollständig die Empfehlungen sind, indem sie die Fähigkeit des Modells bewertet, alle relevanten Items zu finden. Beispielsweise hat man zwei Klassen, die man auf zwei Seiten aufteilen will. Recall betrachtet alles von einer Klasse und berechnet, wie viel richtig klassifiziert wurde. (Eselsbrücke: Rec**ALL** looks at **ALL** elements). Ein Modell mit hohem Recall hat wenige falsche Negative, was bedeutet, dass die meisten relevanten Items in den Empfehlungen enthalten sind.\n",
    "\n",
    "Ein Modell kann hohe Precision haben, aber niedrigen Recall, wenn es sehr selektiv ist und nur die offensichtlich relevanten Items empfiehlt. Umgekehrt kann ein Modell hohen Recall haben, aber niedrige Precision, wenn es viele Items empfiehlt, von denen einige irrelevant sind.\n",
    "\n",
    "Das Ziel ist oft, ein Gleichgewicht zwischen Precision und Recall zu finden, je nach den spezifischen Anforderungen der Anwendung. In einigen Fällen kann es wichtiger sein, alle relevanten Items zu finden (hoher Recall), während in anderen Fällen die Genauigkeit der Empfehlungen (hohe Precision) wichtiger ist.\n",
    "\n",
    "Erklärung aus: https://www.youtube.com/watch?v=qWfzIYCvBqo"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Precision@N\n",
    "Precision@N misst, wie viele der Top-N empfohlenen Items tatsächlich relevant sind. Ein hoher Wert zeigt, dass die empfohlenen Items von guter Qualität sind, da sie tatsächlich den Vorlieben des Nutzers entsprechen. Ein niedriger Wert zeigt, dass die Empfehlungen viele irrelevante Items enthalten.\n",
    "\n",
    "Formel:\n",
    "\n",
    "Precision@N = Anzahl der relevanten Items unter den Top-N Empfehlungen / N\n",
    "\n",
    " Der Relevanz-Schwellenwert beeinflusst die Anzahl der relevanten Items. Ein höherer Schwellenwert bedeutet, dass nur die am besten bewerteten Items als relevant betrachtet werden, was die Precision erhöhen könnte, da nur wenige, aber hoch bewertete Items als relevant gelten. Ein niedrigerer Schwellenwert bedeutet, dass auch schwächer bewertete Items als relevant zählen, was die Precision verringern kann, da mehr irrelevante Items in die Top-N-Empfehlungen aufgenommen werden könnten.\n",
    " \n",
    "Für die Wahl des Schwellenwerts kommt es für mich darauf an, wofür mein Empfehlungssystem (RSY) verwendet werden soll. Beispielsweise würde ich in medizinischen Anwendungen eher einen hohen Schwellenwert wählen, da es dort wichtig ist, so wenige falsche Positive (FP) wie möglich zu haben. Hingegen würde ich bei einem Informationstool einen niedrigen Schwellenwert wählen, da es dort wichtiger sein könnte, dass der Benutzer alle möglichen Ergebnisse finden kann und selbst abwägen kann, was er anschauen möchte.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:03:01.589469Z",
     "start_time": "2025-04-25T15:03:01.577634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Precision@N berechnen\n",
    "def precision_at_n(predictions, relevant_items, N=15, threshold=4.0):\n",
    "    # Filtere relevante Items\n",
    "    relevant_items = [item for item in relevant_items if item[1] >= threshold]\n",
    "    \n",
    "    # Berechne die Top-N Empfehlungen\n",
    "    top_n_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:N]\n",
    "    \n",
    "    # Berechne Precision\n",
    "    relevant_in_top_n = sum(1 for item in top_n_predictions if item[0] in [x[0] for x in relevant_items])\n",
    "    return relevant_in_top_n / N if N > 0 else 0"
   ],
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Recall@N\n",
    "Recall@N misst, wie viele der relevanten Items im Testset in den Top-N Empfehlungen enthalten sind.  Ein hoher Wert zeigt, dass das Modell viele der relevanten Items empfiehlt, auch wenn sie nicht die höchste Punktzahl haben. Ein niedriger Wert deutet darauf hin, dass viele relevante Items übersehen wurden.\n",
    "\n",
    "Fromel:\n",
    "\n",
    "Recall@N = Anzahl der relevanten Items in den Top-N Empfehlungen / Anzahl der relevanten Items im Testset\n",
    "\n",
    "Der Schwellenwert beeinflusst die Anzahl der relevanten Items, die als Ziel für die Empfehlungen gelten. Ein niedrigerer Schwellenwert führt zu mehr relevanten Items und kann den Recall erhöhen, da es einfacher ist, mehr relevante Items in den Top-N-Empfehlungen zu finden. Ein höherer Schwellenwert führt zu weniger relevanten Items und kann den Recall verringern, da weniger Items als relevant betrachtet werden.\n",
    "\n",
    "Für die Wahl des Schwellenwerts kommt es darauf an, wofür mein Empfehlungssystem (RSY) verwendet werden soll. Ein niedriger Schwellenwert ist sinnvoll, wenn es besonders wichtig ist, möglichst alle relevanten Items zu identifizieren, auch wenn dies bedeutet, dass einige irrelevante Items ebenfalls erfasst werden. Dies ist beispielsweise in der medizinischen Diagnostik entscheidend, um sicherzustellen, dass keine relevanten Krankheitsfälle übersehen werden. Ebenso ist ein hoher Recall bei Such- und Rettungsaktionen wichtig, um alle möglichen Hinweise zu berücksichtigen. In der Betrugserkennung und bei Spam-Filtern hilft ein hoher Recall, alle potenziell betrügerischen Transaktionen bzw. Spam-Nachrichten zu identifizieren. Insgesamt sollte der Schwellenwert so gewählt werden, dass er die spezifischen Anforderungen und Ziele der Anwendung optimal unterstützt."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:03:04.129391Z",
     "start_time": "2025-04-25T15:03:04.113585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Recall@N berechnen\n",
    "def recall_at_n(predictions, relevant_items, N=15, threshold=4.0):\n",
    "    # Filtere relevante Items\n",
    "    relevant_items = [item for item in relevant_items if item[1] >= threshold]\n",
    "    \n",
    "    # Berechne die Top-N Empfehlungen\n",
    "    top_n_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:N]\n",
    "    \n",
    "    # Berechne Recall\n",
    "    relevant_in_top_n = sum(1 for item in top_n_predictions if item[0] in [x[0] for x in relevant_items])\n",
    "    return relevant_in_top_n / len(relevant_items) if len(relevant_items) > 0 else 0"
   ],
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train_Validate Daten Einlesen"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_dir = Path(\"Data/Train_Test_validate\")\n",
    "csv_path_train_set_1 = output_dir / \"train_set_1.csv\"\n",
    "csv_path_train_set_2 = output_dir / \"train_set_2.csv\"\n",
    "csv_path_train_set_3 = output_dir / \"train_set_3.csv\"\n",
    "csv_path_train_set_4 = output_dir / \"train_set_4.csv\"\n",
    "csv_path_train_set_5 = output_dir / \"train_set_5.csv\"\n",
    "csv_path_validate_masked_1 = output_dir / \"validate_masked_1.csv\"\n",
    "csv_path_validate_masked_2 = output_dir / \"validate_masked_2.csv\"\n",
    "csv_path_validate_masked_3 = output_dir / \"validate_masked_3.csv\"\n",
    "csv_path_validate_masked_4 = output_dir / \"validate_masked_4.csv\"\n",
    "csv_path_validate_masked_5 = output_dir / \"validate_masked_5.csv\"\n",
    "train_set_1 = pd.read_csv(csv_path_train_set_1)\n",
    "train_set_2 = pd.read_csv(csv_path_train_set_2)\n",
    "train_set_3 = pd.read_csv(csv_path_train_set_3)\n",
    "train_set_4 = pd.read_csv(csv_path_train_set_4)\n",
    "train_set_5 = pd.read_csv(csv_path_train_set_5)\n",
    "validate_masked_1 = pd.read_csv(csv_path_validate_masked_1)\n",
    "validate_masked_2 = pd.read_csv(csv_path_validate_masked_2)\n",
    "validate_masked_3 = pd.read_csv(csv_path_validate_masked_3)\n",
    "validate_masked_4 = pd.read_csv(csv_path_validate_masked_4)\n",
    "validate_masked_5 = pd.read_csv(csv_path_validate_masked_5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Optimize hyperparameters of baseline RS (6 points)\n",
    "Optimize the hyperparameters $\\beta_u$ and $\\beta_i$ for the baseline RS from exercise 2 based on the RMSE metric. To save computation time find a reasonable maximum value for the betas. Explain your approach and your solution.\n",
    "Plot the MAE, RMSE, Precision@N, Recall@N as functions of the betas.\n",
    "\n",
    "Which metric would you use for hyperparameter tuning? Explain your decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nochmal durch gehen kleinere Werte precission und recal nicht immer gleiche Werte\n",
    "## Mein Ansatz\n",
    "Ich gehe hier wiefolgt vor:\n",
    "\n",
    "Ich nehme eine Liste von Werte für meine Hyperparameter Betas. Anschliessend iteriere ich über jeden einzelnen Wert und berechne aus dem Bias den MAE, RMSE, Prcision@N und Recall@N. Dabei fand ich den besten Wert, wenn man nur den RMSE Wert anschaut, bei $b_u$ = 1 und $b_i$ = 5 mit einem RMSE Wert von 1.0192.\n",
    "\n",
    "## Was würde ich nehmen um den Hyperparameter zu tunen?\n",
    "Ich würde, wie auch in der Aufgabe vorgesehen, RMSE (Root Mean Squared Error) für das Hyperparameter-Tuning verwenden, jedoch würde ich zusätzlich noch die Werte Precision@N und Recall@N verwenden. Diese beiden Metriken bieten wertvolle Informationen zur Performance des Empfehlungssystems, da sie die Qualität der Empfehlungen im Hinblick auf die tatsächlich relevanten Items für die Nutzer widerspiegeln.\n",
    "\n",
    "Durch die Kombination von RMSE, Precision@N und Recall@N könnte man ein ausgewogenes Tuning durchführen, das sowohl die Vorhersagegenauigkeit als auch die Relevanz der Empfehlungen optimiert. Das könnte auch dazu führen, dass ein Modell gefunden werden kann, das in der Praxis eine bessere Nutzererfahrung bietet, da es nicht nur die Bewertungshäufigkeit berücksichtigt, sondern auch die tatsächliche Relevanz der Vorschläge für den jeweiligen Nutzer.\n",
    "\n",
    "Würde ich also diese Metriken Benutzen, wäre der beste Wert für $b_u$ = 0.1 und $b_i$ = 10 mit den Werten:\n",
    "- RMSE=1.023\n",
    "- Precision@N=1.0\n",
    "- Recall@N=0.0270"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Anpassung, da ich true und prediction am besten direkt hier berechne deshalb compute_rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def compute_rmse(mu, b_u, b_i, test_df):\n",
    "    preds = []   # Liste zur Speicherung der vorhergesagten Bewertungen\n",
    "    actuals = [] # Liste zur Speicherung der tatsächlichen Bewertungen\n",
    "    \n",
    "    # Iteration über alle Zeilen des Test-Datensatzes\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Extrahiere Nutzer-ID, Film-ID und tatsächliche Bewertung aus der aktuellen Zeile\n",
    "        u, i, true_rating = row[\"userId\"], row[\"movieId\"], row[\"rating\"]\n",
    "        \n",
    "        # Berechne die vorhergesagte Bewertung:\n",
    "        # globale Durchschnittsbewertung + Nutzer-Bias + Item-Bias\n",
    "        # Falls kein Bias vorhanden ist, verwende 0 als Standardwert\n",
    "        pred_rating = mu + b_u.get(u, 0) + b_i.get(i, 0)\n",
    "        \n",
    "        # Speichere die Vorhersage und die tatsächliche Bewertung\n",
    "        preds.append(pred_rating)\n",
    "        actuals.append(true_rating)\n",
    "    \n",
    "    # Berechne und gib die RMSE zwischen den tatsächlichen und vorhergesagten Bewertungen zurück\n",
    "    return np.sqrt(mean_squared_error(actuals, preds))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:25.157979Z",
     "start_time": "2025-04-25T15:03:06.731718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "#Grob testen der Betas\n",
    "beta_values = [0.1, 1, 5, 10, 20]\n",
    "rmse_list = []\n",
    "mae_values = []\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "\n",
    "for beta_u in beta_values:\n",
    "    for beta_i in beta_values:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iteration auf 5 gesetzt, um einen Trend zu sehen\n",
    "        mu, b_u, b_i = calculate_biases(train_set_1, beta_u=beta_u, beta_i=beta_i, iteration=3)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # RMSE berechnen\n",
    "        rmse = compute_rmse(mu, b_u, b_i, validate_masked_1)\n",
    "\n",
    "        # MAE berechnen\n",
    "        predictions = [mu + b_u.get(u, 0) + b_i.get(i, 0) for u, i in zip(validate_masked_1[\"userId\"], validate_masked_1[\"movieId\"])]\n",
    "        true_ratings = validate_masked_1[\"rating\"].values\n",
    "        mae = mean_absolute_error(true_ratings, predictions)\n",
    "\n",
    "        # Precision@N und Recall@N berechnen (falls relevant_items definiert ist)\n",
    "        precision = precision_at_n(list(zip(validate_masked_1[\"movieId\"], predictions)), relevant_items=validate_masked_1[[\"movieId\", \"rating\"]].values)\n",
    "        recall = recall_at_n(list(zip(validate_masked_1[\"movieId\"], predictions)), relevant_items=validate_masked_1[[\"movieId\", \"rating\"]].values)\n",
    "\n",
    "        # Speichern der Ergebnisse\n",
    "        rmse_list.append((beta_u, beta_i, rmse))\n",
    "        mae_values.append((beta_u, beta_i, mae))\n",
    "        precision_values.append((beta_u, beta_i, precision))\n",
    "        recall_values.append((beta_u, beta_i, recall))\n",
    "\n",
    "        print(f\"β_u: {beta_u}, β_i: {beta_i}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, Precision@N: {precision:.4f}, Recall@N: {recall:.4f}, Dauer: {end_time - start_time:.1f} Sekunden\")\n",
    "\n",
    "# Ergebnisse in DataFrame umwandeln\n",
    "df_results = pd.DataFrame(rmse_list, columns=[\"beta_u\", \"beta_i\", \"rmse\"])\n",
    "df_mae = pd.DataFrame(mae_values, columns=[\"beta_u\", \"beta_i\", \"mae\"])\n",
    "df_precision = pd.DataFrame(precision_values, columns=[\"beta_u\", \"beta_i\", \"precision\"])\n",
    "df_recall = pd.DataFrame(recall_values, columns=[\"beta_u\", \"beta_i\", \"recall\"])\n",
    "\n",
    "# RMSE Heatmap\n",
    "pivot_rmse = df_results.pivot(index=\"beta_u\", columns=\"beta_i\", values=\"rmse\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_rmse, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "plt.title(\"RMSE Heatmap für verschiedene β-Werte\")\n",
    "plt.xlabel(\"β_i\")\n",
    "plt.ylabel(\"β_u\")\n",
    "plt.show()\n",
    "\n",
    "# MAE Heatmap\n",
    "pivot_mae = df_mae.pivot(index=\"beta_u\", columns=\"beta_i\", values=\"mae\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_mae, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "plt.title(\"MAE Heatmap für verschiedene β-Werte\")\n",
    "plt.xlabel(\"β_i\")\n",
    "plt.ylabel(\"β_u\")\n",
    "plt.show()\n",
    "\n",
    "# Precision@N Heatmap\n",
    "pivot_precision = df_precision.pivot(index=\"beta_u\", columns=\"beta_i\", values=\"precision\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_precision, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "plt.title(\"Precision@N Heatmap für verschiedene β-Werte\")\n",
    "plt.xlabel(\"β_i\")\n",
    "plt.ylabel(\"β_u\")\n",
    "plt.show()\n",
    "\n",
    "# Recall@N Heatmap\n",
    "pivot_recall = df_recall.pivot(index=\"beta_u\", columns=\"beta_i\", values=\"recall\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_recall, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "plt.title(\"Recall@N Heatmap für verschiedene β-Werte\")\n",
    "plt.xlabel(\"β_i\")\n",
    "plt.ylabel(\"β_u\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "β_u: 0.1, β_i: 0.1, RMSE: 0.9928, MAE: 0.7655, Precision@N: 0.8667, Recall@N: 0.0231, Dauer: 148.2 Sekunden\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[173], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Iteration auf 5 gesetzt, um einen Trend zu sehen\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m mu, b_u, b_i \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_biases\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_set_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta_u\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta_u\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miteration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# RMSE berechnen\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[34], line 28\u001B[0m, in \u001B[0;36mcalculate_biases\u001B[1;34m(df, beta_u, beta_i, iteration)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# Update b_i\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m movie_id \u001B[38;5;129;01min\u001B[39;00m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmovieId\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39munique():\n\u001B[1;32m---> 28\u001B[0m     movie_ratings \u001B[38;5;241m=\u001B[39m df[\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmovieId\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmovie_id\u001B[49m]\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;66;03m# Berechne den Zähler für b_i (Summe der Abweichungen der Bewertungen des Films im vergleich zur Duchschnittbewertung im ganzen Systemund User-Bias)\u001B[39;00m\n\u001B[0;32m     30\u001B[0m     zähler \u001B[38;5;241m=\u001B[39m ((movie_ratings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrating\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m-\u001B[39m mu \u001B[38;5;241m-\u001B[39m movie_ratings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muserId\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(b_u))\u001B[38;5;241m.\u001B[39msum())\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\RSY\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[0;32m     70\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[1;32m---> 72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\RSY\\lib\\site-packages\\pandas\\core\\arraylike.py:42\u001B[0m, in \u001B[0;36mOpsMixin.__eq__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__eq__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__eq__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cmp_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meq\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\RSY\\lib\\site-packages\\pandas\\core\\series.py:6243\u001B[0m, in \u001B[0;36mSeries._cmp_method\u001B[1;34m(self, other, op)\u001B[0m\n\u001B[0;32m   6240\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m extract_array(other, extract_numpy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, extract_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   6242\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 6243\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomparison_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6245\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(res_values, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\RSY\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:290\u001B[0m, in \u001B[0;36mcomparison_op\u001B[1;34m(left, right, op)\u001B[0m\n\u001B[0;32m    287\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001B[0;32m    289\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 290\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43m_na_arithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_cmp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res_values\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\RSY\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:165\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[1;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[0;32m    162\u001B[0m     func \u001B[38;5;241m=\u001B[39m partial(expressions\u001B[38;5;241m.\u001B[39mevaluate, op)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 165\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cmp \u001B[38;5;129;01mand\u001B[39;00m (is_object_dtype(left\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(right)):\n\u001B[0;32m    168\u001B[0m         \u001B[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001B[39;00m\n\u001B[0;32m    169\u001B[0m         \u001B[38;5;66;03m#  on the non-missing values)\u001B[39;00m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001B[39;00m\n\u001B[0;32m    171\u001B[0m         \u001B[38;5;66;03m#  incorrectly, see GH#32047\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\RSY\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:241\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(op, a, b, use_numexpr)\u001B[0m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m op_str \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_numexpr:\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;66;03m# error: \"None\" not callable\u001B[39;00m\n\u001B[1;32m--> 241\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\RSY\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001B[0m, in \u001B[0;36m_evaluate_standard\u001B[1;34m(op, op_str, a, b)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _TEST_MODE:\n\u001B[0;32m     69\u001B[0m     _store_test_result(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 - Collaborative filtering; item-based and user-based (12 points)\n",
    "In this exersise we will build several different collaborative-filtering RS based on nearest neighbour technique, both in terms of item and user. \n",
    "\n",
    "Implement:\n",
    "1. a RS based on the $K$ most similar items (K nearest neighbours). Similarity shall be calculated based on *cosine similarity*. \n",
    "2. a RS based on the $K$ most similar items (K nearest neighbours). Similarity shall be calculated based on *Pearson Correlation Coefficienct*. \n",
    "3. a RS based on the $K$ most similar users (K nearest neighbours). Similarity shall be calculated based on *cosine similarity*. \n",
    "4. a RS based on the $K$ most similar users (K nearest neighbours). Similarity shall be calculated based on *Pearson Correlation Coefficienct*. \n",
    "\n",
    "Each should have a default $K$ of 30.\n",
    "\n",
    "Explain how you handle NaN values in the user rating matrix when computing similarities? What other preparations are useful such as normalization and mean centering?\n",
    "\n",
    "Describe the two similarity metrics.\n",
    "\n",
    "Show the top 20 recommended items for user ids 3, 5 and 7."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Umgang mit NaN-Werten\n",
    "\n",
    "Ich ersetze die NaN-Werte in der Cosine Similarity (für sowohl Items als auch Users) mit 0, und zwar erst nachdem ich den Mittelwert pro Item bzw. User abgezogen habe. Dies stellt sicher, dass die Cosine Similarity-Funktion von scikit-learn korrekt berechnet werden kann, da diese Bibliothek keine NaN-Werte unterstützt. Bei der Pearson Similarity ersetze ich die NaN-Werte ebenfalls mit 0, allerdings nachdem ich die URM (User-Rating-Matrix) zentriert habe. Der Ersatz von NaN durch 0 ist eine pragmatische Lösung, da fehlende Bewertungen als „nicht vorhanden“ betrachtet werden, ohne den Berechnungsprozess zu stören.\n",
    "\n",
    "In der Funktion predict_ratings_item_based und predict_ratings_user_based hingegen vermeide ich NaN-Werte direkt, indem ich alle NaN-Werte vorher mit dropna() entferne. Dadurch wird vermieden, dass fehlende Bewertungen den Vorhersageprozess beeinflussen, und es ist keine Notwendigkeit, NaN-Werte nachträglich zu ersetzen."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_urm(data, index, colums, values):\n",
    "    urm = data.pivot(index=index, columns=colums, values=values)\n",
    "    return urm\n",
    "\n",
    "urm = create_urm(test_masked, \"userId\", \"movieId\", \"rating\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "Die Cosine Similarity misst die Ähnlichkeit zwischen zwei Items, indem sie den Winkel zwischen ihren Bewertungsvektoren betrachtet. Je kleiner der Winkel, desto ähnlicher sind die Items im Bewertungsschema der Nutzer.\n",
    "\n",
    "Um Verzerrungen durch unterschiedliche Bewertungsskalen zu vermeiden – z.B. wenn einige Nutzer generell strenger oder grosszügiger bewerten – wird häufig ein Mean-Centering durchgeführt: Dabei wird von jeder Bewertung der Durchschnittswert des jeweiligen Items (oder Nutzers) abgezogen.\n",
    "\n",
    "Dadurch vergleicht die Cosine Similarity nicht die absoluten Werte, sondern die Abweichungen vom Mittelwert, also das tatsächliche Bewertungsmuster. Das macht die Ähnlichkeitsberechnung robuster und aussagekräftiger.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_items(matrix):\n",
    "    # Mean-Centering pro Item\n",
    "    item_means = matrix.mean(axis=0) #axis = 0 bedeutet den Mittelwert pro Spalte zu berechnen\n",
    "    matrix_centered = matrix.sub(item_means, axis=1) # subtrahiert spaltenweise (axis = 1) den jeweiligen Mittelwert des Items ab\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        cosine_similarity(np.nan_to_num(matrix_centered.T)),\n",
    "        index=matrix.columns,\n",
    "        columns=matrix.columns\n",
    "    )\n",
    "\n",
    "def cosine_similarity_users(matrix):\n",
    "    # Mean-Centering pro User\n",
    "    user_means = matrix.mean(axis=1) #axis = 1 bedeutet den Mittelwert pro Zeile zu berechnen\n",
    "    matrix_centered = matrix.sub(user_means, axis=0) # subtrahiert zeilenweise (axis = 0) den jeweiligen Mittelwert des Users ab\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        cosine_similarity(np.nan_to_num(matrix_centered)),\n",
    "        index=matrix.index,\n",
    "        columns=matrix.index\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pearson Similarity\n",
    "Die Pearson Similarity misst die lineare Korrelation zwischen zwei Items oder Nutzern, basierend auf deren gemeinsamen Bewertungen. Sie betrachtet dabei nicht nur die Richtung der Bewertungen, sondern auch, ob hohe Bewertungen bei einem Item (bzw. Nutzer) mit hohen Bewertungen beim anderen einhergehen – unabhängig vom absoluten Bewertungsniveau.\n",
    "\n",
    "Um individuelle Bewertungstendenzen auszugleichen, wird vor der Berechnung der Pearson Similarity ein Mean-Centering durchgeführt: Bei der Item-basierten Variante wird von jeder Bewertung der Mittelwert des jeweiligen Items abgezogen; bei der nutzerbasierten Variante erfolgt die Zentrierung zeilenweise, also pro Nutzer. So werden systematisch grosszügige oder strenge Bewertungsschemata normalisiert.\n",
    "\n",
    "Anschliessend wird die Korrelation zwischen den zentrierten Vektoren berechnet. Da in der Praxis häufig nicht alle Nutzer alle Items bewerten, entstehen Lücken im Rating-Matrix – diese werden durch gezieltes Beibehalten oder Ersetzen von fehlenden Werten (NaN) berücksichtigt: Bei Items ignoriert pd.corr() diese NaN-Werte automatisch während der Korrelation; bei Nutzern hingegen werden sie nach dem Zentrieren direkt mit 0 ersetzt. Das sorgt für eine robuste Berechnung, selbst bei spärlich besetzten Daten."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pearson_similarity_items(matrix):\n",
    "    # Mittelwert zentrieren je Item (Spalte)\n",
    "    item_means = matrix.mean(axis=1)  # Mittelwert pro Item (Spalte)\n",
    "    matrix_centered = matrix.sub(item_means, axis=0)  # Subtrahiere Mittelwert von jedem Item (Spalte)\n",
    "    \n",
    "    # Berechne die Pearson-Ähnlichkeit zwischen den Items\n",
    "    pearson_sim_matrix = matrix_centered.corr(method='pearson').fillna(0)\n",
    "\n",
    "    return pearson_sim_matrix\n",
    "\n",
    "\n",
    "\n",
    "def pearson_similarity_users(matrix):\n",
    "    # Mittelwert zentrieren je User (Zeile)\n",
    "    centered = matrix.sub(matrix.mean(axis=1), axis=0).fillna(0)# subtrahiert zeilenweise den jeweiligen Mittelwert pro Zeile des Items ab und ersetzt anschliessend alle NA Werte mit 0\n",
    "    # Jetzt Zeilen miteinander korrelieren (User-User-Similarity) und anschliessend die NA-Werte mit 0 ersetzen\n",
    "    similarity = centered.T.corr().fillna(0)\n",
    "    return similarity"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction Item-Based"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_ratings_item_based(user_id, item_similarity, urm_, k=30):\n",
    "    user_ratings = urm_.loc[user_id]\n",
    "    user_rated_items = user_ratings.dropna().index\n",
    "    \n",
    "    all_items = urm_.columns\n",
    "    predictions = {}\n",
    "\n",
    "    for target_item in all_items:\n",
    "        if target_item in user_rated_items:\n",
    "            continue  # Keine Vorhersage für bereits bewertete Items\n",
    "\n",
    "        # Ähnlichkeiten zum Ziel-Item für alle vom User bewerteten Items\n",
    "        sims = item_similarity.loc[target_item, user_rated_items]\n",
    "\n",
    "        # Bewertungen des Users zu diesen Items\n",
    "        ratings = user_ratings.loc[user_rated_items]\n",
    "\n",
    "        # Top-k ähnlichste Items auswählen (nach Betrag der Ähnlichkeit sortieren)\n",
    "        top_k = sims.abs().sort_values(ascending=False).head(k).index\n",
    "        top_sims = sims.loc[top_k]\n",
    "        top_ratings = ratings.loc[top_k]\n",
    "\n",
    "        numerator = (top_sims * top_ratings).sum()\n",
    "        denominator = top_sims.abs().sum()\n",
    "\n",
    "        if denominator != 0:\n",
    "            predictions[target_item] = numerator / denominator\n",
    "        else:\n",
    "            predictions[target_item] = np.nan  # oder z. B. globaler Mittelwert als Fallback\n",
    "\n",
    "    # Rückgabe als Serie sortiert\n",
    "    return pd.Series(predictions).dropna().sort_values(ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Top n item similatrity"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def print_top_n_item_similarity(user_ids, urm_, method, movies_df=None, n=20, k=30):\n",
    "    if method == \"cosine\":\n",
    "        item_sim_matrix = cosine_similarity_items(urm_)\n",
    "    elif method == \"pearson\":\n",
    "        item_sim_matrix = pearson_similarity_items(urm_)\n",
    "    else:\n",
    "        print(f\"Invalid method: {method}. Only 'cosine' or 'pearson' are allowed.\")\n",
    "        return\n",
    "        \n",
    "    use_titles = movies_df is not None and \"movieId\" in movies_df.columns and \"title\" in movies_df.columns\n",
    "        \n",
    "    if use_titles:\n",
    "        movies_itembased = movies_df.set_index(\"movieId\")\n",
    "\n",
    "    for uid in user_ids:\n",
    "        if uid in urm_.index:\n",
    "            recs = predict_ratings_item_based(uid, item_sim_matrix, urm_, k)\n",
    "            top_n = recs.head(n)\n",
    "        else:\n",
    "            global_avg_ratings = urm_.mean(axis=0)\n",
    "            top_n = global_avg_ratings.sort_values(ascending=False).head(n)\n",
    "            \n",
    "        top_n.index = top_n.index.astype(int)\n",
    "        if use_titles:\n",
    "            valid_ids = top_n.index.intersection(movies_itembased.index)\n",
    "            movie_titles = movies_itembased.loc[valid_ids, \"title\"]\n",
    "            \n",
    "            results = pd.DataFrame({\n",
    "                \"Predicted Rating\": top_n.loc[valid_ids].values,\n",
    "                \"Movie Title\": movie_titles.values\n",
    "            })\n",
    "            \n",
    "            print(f\"\\nTop {n} recommendations for User {uid} (Item-Based, {method}):\")\n",
    "            print(results.set_index(\"Movie Title\"))\n",
    "        else:\n",
    "            results = pd.DataFrame({\n",
    "                \"Movie ID\": top_n.index,\n",
    "                \"Predicted Rating\": top_n.values\n",
    "            })\n",
    "            \n",
    "            print(f\"\\nTop {n} recommendations for User {uid} (Item-Based, {method}, only Movie IDs):\")\n",
    "            print(results.set_index(\"Movie ID\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_top_n_item_similarity(user_ids = [3,5,7], urm_ = urm, method = \"cosine\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_top_n_item_similarity(user_ids = [3,5,7], urm_ = urm, method = \"pearson\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction user-based"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_ratings_user_based_(user_id, similarity_matrix, rating_matrix, k=30):\n",
    "    #User selbst wurd entfertn da er nicht mit dsich verglichen werden soll\n",
    "    sim_users = similarity_matrix[user_id].drop(user_id).dropna()\n",
    "    #Welche top-k User sind mit Ursprung user Ähnlich\n",
    "    top_k_users = sim_users.sort_values(ascending=False).head(k)\n",
    "    \n",
    "    # Mittels gewichtung wird der Ähnlcihste user gesucht\n",
    "    weighted_sum = (rating_matrix.loc[top_k_users.index].T * top_k_users).T.sum()\n",
    "    sim_sum = top_k_users.abs().sum()\n",
    "    \n",
    "    user_mean = rating_matrix.loc[user_id].mean()\n",
    "    predicted_ratings = user_mean + (weighted_sum / sim_sum) #Addiert den in der Similarity abgezogenen Mittelwert wieder drauf\n",
    "\n",
    "    return predicted_ratings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_top_n_user_similarity(user_ids: list, urm_,method, movies_df = None, n=20, k=30):\n",
    "    if method == \"cosine\":\n",
    "        user_sim_matrix = cosine_similarity_users(urm_)\n",
    "    elif method == \"pearson\":\n",
    "        user_sim_matrix = pearson_similarity_users(urm_)\n",
    "    else:\n",
    "        print(f\"Die Methode ist nicht vorhanden – bitte 'cosine' oder 'pearson' verwenden (nicht '{method}').\")\n",
    "        return\n",
    "\n",
    "    use_titles = movies_df is not None and \"movieId\" in movies_df.columns and \"title\" in movies_df.columns\n",
    "    if use_titles:\n",
    "        movies_user = movies_df.set_index(\"movieId\")\n",
    "\n",
    "    for uid in user_ids:\n",
    "        if uid in urm_.index:\n",
    "            recs = predict_ratings_user_based_(uid, user_sim_matrix, urm_, k)\n",
    "            top_n = recs.sort_values(ascending=False).head(n)\n",
    "        else:\n",
    "            global_avg_ratings = urm_.mean(axis=0)\n",
    "            top_n = global_avg_ratings.sort_values(ascending=False).head(n)\n",
    "\n",
    "        top_n.index = top_n.index.astype(int)\n",
    "\n",
    "        if use_titles:\n",
    "            valid_ids = top_n.index[top_n.index.isin(movies_user.index)]\n",
    "            movie_titles = movies_user.loc[valid_ids, \"title\"]\n",
    "            results = pd.DataFrame({\n",
    "                \"Predicted Rating\": top_n.loc[valid_ids].values,\n",
    "                \"Movie Title\": movie_titles.values\n",
    "            })\n",
    "            print(f\"\\nTop {n} Empfehlungen für User {uid} (User-Based, {method}):\")\n",
    "            print(results.set_index(\"Movie Title\"))\n",
    "        else:\n",
    "            results = pd.DataFrame({\n",
    "                \"Movie ID\": top_n.index,\n",
    "                \"Predicted Rating\": top_n.values\n",
    "            })\n",
    "            print(f\"\\nTop {n} Empfehlungen für User {uid} (User-Based, {method}, nur Movie IDs):\")\n",
    "            print(results.set_index(\"Movie ID\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cosine"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_top_n_user_similarity(user_ids = [3, 5, 7], urm_ = urm, method = \"cosine\", movies_df=movies)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pearson"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_top_n_user_similarity(user_ids = [3, 5, 7], urm_ = urm, method = \"pearson\", movies_df = movies)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hier weiter irgendwas stimmt nicht ich erhalte nur Werte für User\n",
    "### Exercise 6 - Optimize hyperparameter $K$ (6 points)\n",
    "Optimize the hyperparameter $K$ for all RS from the prior exercise optimizing for minimal RMSE. \n",
    "For each RS plot RMSE, Precision@N and Recall@N as a function of $K$. \n",
    "\n",
    "Compare the results of these four RS on the 3 example users. Do the results match your expectation? Describe."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Meine Erwartungen\n",
    "Die Restultate spiegeln nur zum teil meine Erwartungen wieder. Ich erwartete eienrseits ein tieferes RMSE und bessere Werte bei Precision und Recall. Vorallem im bereich der Item Basierten RS. Ich nehme an, dass das daher kommt, dass im Datensatz, den ich zum testen verwendet habe, zuwenig Datne sind und es daher keine genug hohen Werte gab."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_rs_methods(user_ids, urm, true_ratings_df, ks=range(1, 51), N=15):\n",
    "    # Dictionary zur Speicherung der Ergebnisse pro Methode\n",
    "    results = {\n",
    "        \"user_cosine\": [],\n",
    "        \"user_pearson\": [],\n",
    "        \"item_cosine\": [],\n",
    "        \"item_pearson\": []\n",
    "    }\n",
    "    # Mapping von Methodenname zu entsprechender Similarity-Funktion\n",
    "    methods = {\n",
    "        \"user_cosine\": cosine_similarity_users,\n",
    "        \"user_pearson\": pearson_similarity_users,\n",
    "        \"item_cosine\": cosine_similarity_items,\n",
    "        \"item_pearson\": pearson_similarity_items\n",
    "    }\n",
    "    \n",
    "     # Iteration über alle Recommender-Methoden\n",
    "    for method_name, sim_func in methods.items():\n",
    "        # Prüfen, ob es sich um ein user-basiertes Modell handelt\n",
    "        is_user_based = \"user\" in method_name\n",
    "        # Berechne Similarity-Matrix\n",
    "        sim_matrix = sim_func(urm)\n",
    "\n",
    "        # Iteration über alle K-Werte (Anzahl der Nachbarn)\n",
    "        for k in ks:\n",
    "            all_preds = []  # Vorhergesagte Ratings\n",
    "            all_truths = []  # Wahre Ratings\n",
    "            precs = []  # Precision-Werte pro User\n",
    "            recs = []   # Recall-Werte pro User\n",
    "\n",
    "            for uid in user_ids:\n",
    "                # Nur User verwenden, die in der URM enthalten sind\n",
    "                if uid not in urm.index:\n",
    "                    continue\n",
    "\n",
    "                if is_user_based:\n",
    "                    preds = predict_ratings_user_based_(uid, sim_matrix, urm, k)\n",
    "                else:\n",
    "                    preds = predict_ratings_item_based(uid, sim_matrix, urm, k)\n",
    "\n",
    "                # Nur bekannte Bewertungen vergleichen\n",
    "                true_ratings = true_ratings_df[true_ratings_df[\"userId\"] == uid].dropna()\n",
    "                # Vorhersagen mit tatsächlichen Bewertungen vergleichen\n",
    "                for _, row in true_ratings.iterrows():\n",
    "                    movie_id = row[\"movieId\"]\n",
    "                    if movie_id in preds.index:\n",
    "                        all_preds.append(preds[movie_id])\n",
    "                        all_truths.append(row[\"rating\"])\n",
    "\n",
    "                # Precision@N und Recall@N\n",
    "                rec_list = list(preds.items())# (movieId, predicted_rating)\n",
    "                truth_list = list(true_ratings[[\"movieId\", \"rating\"]].itertuples(index=False, name=None))\n",
    "                precs.append(precision_at_n(rec_list, truth_list, N=N))\n",
    "                recs.append(recall_at_n(rec_list, truth_list, N=N))\n",
    "                \n",
    "            # RMSE und Durchschnittswerte berechnen (falls es Vergleichsdaten gibt)\n",
    "            rmse = root_mean_square_error(all_truths, all_preds) if all_truths else None\n",
    "            avg_prec = np.nanmean(precs)\n",
    "            avg_rec = np.nanmean(recs)\n",
    "            # Speichere Ergebnisse (K, RMSE, Precision@N, Recall@N)\n",
    "            results[method_name].append((k, rmse, avg_prec, avg_rec))\n",
    "\n",
    "    return results\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_metrics(results, N):\n",
    "    for method, data in results.items():\n",
    "        ks, rmses, precs, recs = zip(*data)\n",
    "\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.suptitle(f\"Evaluation für {method}\")\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(ks, rmses, marker='o')\n",
    "        plt.title(\"RMSE\")\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"RMSE\")\n",
    "        plt.ylim(bottom=0)\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(ks, precs, marker='o')\n",
    "        plt.title(f\"Precision@{N}\")\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.ylim(bottom=0)\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(ks, recs, marker='o')\n",
    "        plt.title(f\"Recall@{N}\")\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Recall\")\n",
    "        plt.ylim(bottom=0)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DEBUG für aufgabe 8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_ids = [3, 5, 7]  # Beispielnutzer\n",
    "results = evaluate_rs_methods(user_ids, urm, test, ks=np.linspace(1, 40, 20, dtype=int), N=15)\n",
    "plot_metrics(results, N = 15)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7 - Model-based RS: SVD (10 points)\n",
    "In this exercise we will use the unsupervised method *singular value decomposition (SVD)* from the python package *surprise* (https://surpriselib.com, documentation https://surprise.readthedocs.io/en/stable/matrix_factorization.html). SVD can compress much of the information of a matrix in few components.  \n",
    "\n",
    "a)Run the SVD RS and show the results on the three example users from exercise 2. Explain how this algorithm works.\n",
    "\n",
    "Note: A very good general introduction to SVD is this youtube video series starting with https://www.youtube.com/watch?v=gXbThCXjZFM&t=337s . See *Collaborative filtering recommender systems* by Ekstrand et al. *Mining of massive datasets* by Leskovec, Kapitel 11 (2020) and, *Recommender systems: The textbook*, by Aggarwal, chapter 3\n",
    "\n",
    "b) We explore now what latent factors SVD has learned. Generate three sorted lists: Sort the items by their biggest, second biggest and third biggest singlular value component. For each list print the top and bottom 20 items. What do you observe?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Singular Value Decomposition (SVD)\n",
    "Singular Value Decompistion (SVD) ist eine Methode zur Dimensionsreduktion von Daten. SVD nimmt hochdimensionale Daten und reduziert diese auf seine wichtigsten Features und Korrelationen. Ihre Anwendung findet sie unter anderem bei der Lösung von Gleichungssystemen, Bildkompression, Principal Component Analysis (PCA) und eben auch bei Recommender Systemen.\n",
    "\n",
    "Die Grundidee von SVD ist es, eine  $m \\times n$ Matrix $A$ in das Produkt dreier Matrizen zu zerlegen:\n",
    "\n",
    "$$ A = U \\Sigma V^T $$\n",
    "\n",
    "Hierbei sind:\n",
    "- $U$ eine $m \\times m$ orthogonale Matrix, deren Spalten die linken Singulärvektoren von $A$ sind\n",
    "- $\\Sigma$ eine $m \\times n$ Diagonalmatrix, deren Diagonalelemente in abnehmender Reihenfolge die Singulärwerte von $A$ sind. Diese können nur positive Werte annehmen.\n",
    "- $V^T$ die transponierte Form einer $n \\times n$ orthogonalen Matrix, deren Zeilen die rechten Singulärvektoren von $A$ sind\n",
    "\n",
    "Bezogen auf Recommender Systeme wird SVD verwendet um die User-Item Matrix in diese drei Matrizen zu zerlegen. Die Matrix $U$ repräsentiert dann die User, die Matrix $V$ die Items. Diese Matrizen werden auch Latente Repräsentatioen genannt und enthalten die versteckten Merkmale der User und Items. Die Diagonalmatrix $\\Sigma$ enthält die Gewichtungen dieser Merkmale.\n",
    "\n",
    "Nachdem diese Matrizen erzeugt wurden, können die latenten Repräsentationen von Benutzern und Items in $U$ und $V^T$ genutzt werden, um Empfehlungen zu erstellen. Beispielsweise können ähnliche Benutzer oder Items durch Messen der Ähnlichkeit ihrer latenten Repräsentationen identifiziert werden. Ebenfalls kann vorhergesagt werden, wie ein Benutzer ein noch nicht bewertetes Item einschätzen würde, indem das Skalarprodukt der latenten Repräsentation des Benutzers in $U$ mit der des Items in $V^T$ gebildet wird.\n",
    "\n",
    "Die Anzahl der Singulärwerte, die verwendet werden, um die User-Item-Matrix zu rekonstruieren, wird als Hyperparameter $k$ bezeichnet. Je größer $k$ ist, desto genauer wird die Matrix rekonstruiert, jedoch steigt auch die Gefahr von Overfitting. Die Wahl von $k$ ist also ein wichtiger Aspekt bei der Anwendung von SVD.\n",
    "\n",
    "SVD hat den Vorteil, dass es einfach zu interpretieren ist, auf jeder Matrix angewendet werden kann und gut auf grössere Datenmengen skaliert."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### a)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Daten vorbereiten\n",
    "def prepare_data(df):\n",
    "    reader = Reader(rating_scale=(0.5, 5))\n",
    "    data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    return trainset, testset\n",
    "\n",
    "# SVD Modell trainieren\n",
    "def train_svd(trainset):\n",
    "    svd = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "    svd.fit(trainset)\n",
    "    return svd\n",
    "\n",
    "# Vorhersagen für einen Benutzer machen\n",
    "def get_svd_recommendations(svd, df, user_id, movies, n=20):\n",
    "    # Filme, die der Benutzer bereits bewertet hat\n",
    "    rated_movies = df[df['userId'] == user_id]['movieId'].unique()\n",
    "    \n",
    "    # Alle Filme, die der Benutzer nicht bewertet hat\n",
    "    all_movies = df['movieId'].unique()\n",
    "    unrated_movies = [movie for movie in all_movies if movie not in rated_movies]\n",
    "    \n",
    "    # Vorhersagen machen\n",
    "    predictions = []\n",
    "    for movie_id in unrated_movies:\n",
    "        pred = svd.predict(user_id, movie_id)\n",
    "        predictions.append((movie_id, pred.est))\n",
    "    \n",
    "    # Nach höchster Bewertung sortieren\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Top-N Empfehlungen ausgeben\n",
    "    print(f\"\\nTop {n} SVD-Empfehlungen für Benutzer {user_id}:\")\n",
    "    for i, (movie_id, rating) in enumerate(predictions[:n], 1):\n",
    "        movie_title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
    "        print(f\"{i}. {movie_title} - Vorhergesagte Bewertung: {rating:.2f}\")\n",
    "\n",
    "# Annahme: ratings und movies DataFrames sind bereits geladen\n",
    "trainset, testset = prepare_data(ratings)\n",
    "svd = train_svd(trainset)\n",
    "\n",
    "# Beispielbenutzer aus Aufgabe 2\n",
    "example_users = [1, 3, 7]  # Beispiel-User-IDs anpassen\n",
    "\n",
    "for user in example_users:\n",
    "    get_svd_recommendations(svd, ratings, user, movies)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Die Empfehlungen scheinen hier individueller zu sein, da die Benutzer unterschiedlichere Empfehlungen bekommen. Ausserdem gibt es nicht so viele 5 Sterne Bewertungen wie bei den Collaborative Filtering RS. Auf den ersten Blick scheinen es auch eher bekanntere Filme zu sein, welche empfohlen werden."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### b)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import display\n",
    "# Berechne die Durchschnittsbewertungen je Film\n",
    "avg_ratings = ratings.groupby(\"movieId\")[\"rating\"].mean().reset_index()\n",
    "avg_ratings.columns = [\"movieId\", \"avg_rating\"]\n",
    "\n",
    "# Zugriff auf die Item-Faktoren (q_i) im trainierten Modell\n",
    "item_factors = svd.qi  # shape: (n_items, n_factors)\n",
    "item_inner_ids = list(range(len(item_factors)))  # surprise-interne IDs\n",
    "item_raw_ids = [svd.trainset.to_raw_iid(iid) for iid in item_inner_ids]  # movieId (als Strings!)\n",
    "\n",
    "# Erstelle DataFrame mit Faktoren\n",
    "item_df = pd.DataFrame(item_factors, columns=[f\"f{i+1}\" for i in range(item_factors.shape[1])])\n",
    "item_df[\"movieId\"] = item_raw_ids\n",
    "item_df[\"movieId\"] = item_df[\"movieId\"].astype(int)  # Für Merge nötig\n",
    "\n",
    "# Füge Titel, Genre und Durchschnittsbewertung hinzu\n",
    "item_df = item_df.merge(movies[[\"movieId\", \"title\", \"genres\"]], on=\"movieId\", how=\"left\")\n",
    "item_df = item_df.merge(avg_ratings, on=\"movieId\", how=\"left\")\n",
    "\n",
    "# Für die ersten 3 latenten Faktoren: sortiere Items nach deren Einfluss\n",
    "for i in range(3):\n",
    "    col = f\"f{i+1}\"\n",
    "    sorted_items = item_df.sort_values(by=col, ascending=False)\n",
    "\n",
    "    # Top 20\n",
    "    top_20 = sorted_items.head(20)[[\"title\", \"avg_rating\", \"genres\"]].copy()\n",
    "    top_20[\"avg_rating\"] = top_20[\"avg_rating\"].round(2)\n",
    "    top_20.columns = [f\"Titel (Top 20 Filme nach Faktor {i+1}) \", \"Durchschnittsbewertung\", \"Genre\"]\n",
    "    display(top_20)\n",
    "\n",
    "    # Bottom 20\n",
    "    bottom_20 = sorted_items.tail(20)[[\"title\", \"avg_rating\", \"genres\"]].copy()\n",
    "    bottom_20[\"avg_rating\"] = bottom_20[\"avg_rating\"].round(2)\n",
    "    bottom_20.columns = [f\"Titel (Bottom 20 Filme nach Faktor {i+1})\", \"Durchschnittsbewertung\", \"Genre\"]\n",
    "    display(bottom_20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Anhand er Ausgaben kann ich persönlich kein wirkliches Muster erkennen, dafür kenne ich zuwenig Filme. Aber ich vermute anhand der Genres dass in Faktor 3 eher Action gegen Comedy/Drama verglichen wird. Beim Faktor 2 erkenne ich lediglich, dass in beiden Listen viel das Genres Comedy vertreten ist. Aber bei Faktor 1 erkenne ich überhaupt nichts.\n",
    "\n",
    "Laut meiner Recherche, sollten die 3 Faktoren folgendes machen:\n",
    "- Der **erste Faktor** spiegelt die dominanten, allgemeinen Vorlieben der Nutzer wider. Dieser Faktor erfasst die größte Varianz in den Bewertungen und könnte populäre oder Mainstream-Filme widerspiegeln, die von vielen Nutzern hoch bewertet werden. Filme, die in diesem Faktor hohe Werte haben, sind typischerweise beliebt und werden von einer breiten Zuschauergruppe geschätzt.\n",
    "- Der **zweite Faktor** hingegen erfasst spezifischere Vorlieben der Nutzer, wie bestimmte Genres oder Filmstile. Hierbei geht es weniger um populäre Filme im Allgemeinen, sondern um Präferenzen, die mit bestimmten Genres.Dieser Faktor könnte eine Sub-Präferenz darstellen, die in den Bewertungen der Nutzer zum Tragen kommt, und ermöglicht es dem Modell, Filme zu empfehlen, die zu den bevorzugten Genres eines Nutzers passen.\n",
    "- Der **dritte Faktor** beschreibt eine noch spezifischere Dimension der Nutzerpräferenzen. Dieser Faktor erfasst eher Nischeninteressen oder weniger offensichtliche Filmmerkmale. Es geht hierbei oft um besondere kulturelle Merkmale, künstlerische Filme oder weniger Mainstream-Inhalte, die von einer spezifischen Nutzergruppe geschätzt werden. Filme, die in diesem Faktor hoch bewertet werden, könnten beispielsweise künstlerisch anspruchsvolle oder philosophische Werke sein, die nur von einer kleineren Zielgruppe bevorzugt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8 - Optimize hyperparameter $k$ or `n_factors` (4 points)\n",
    "Optimize the hyperparameter, representing the number of greatest SVD components used for the truncated reconstruction of the user item matrix, to minimize RMSE.\n",
    "Plot RMSE, Precision@N and Recall@N as a function of this hyperparameter. Finally output all performance metrics from exercise 3 for the optimal $k$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:14:26.702108Z",
     "start_time": "2025-04-25T15:09:26.385062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Precision@N und Recall@N berechnen\n",
    "def get_top_n(predictions, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_k = user_ratings[:k]\n",
    "\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in top_k)\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in top_k)\n",
    "\n",
    "        precision = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recall = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls)\n",
    "\n",
    "# Optimierung von n_factors\n",
    "def optimize_n_factors(ratings, n_factors_list, k=10):\n",
    "    trainset, testset = prepare_data(ratings)\n",
    "    \n",
    "    rmse_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "\n",
    "    for n_factors in n_factors_list:\n",
    "        svd = SVD(n_factors=n_factors, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "        svd.fit(trainset)\n",
    "        predictions = svd.test(testset)\n",
    "        \n",
    "        rmse = accuracy.rmse(predictions, verbose=False)\n",
    "        precision, recall = precision_recall_at_k(predictions, k=k)\n",
    "        \n",
    "        rmse_list.append(rmse)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        \n",
    "        print(f\"n_factors={n_factors} | RMSE={rmse:.4f} | Precision@{k}={precision:.4f} | Recall@{k}={recall:.4f}\")\n",
    "\n",
    "    # Plotten\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(n_factors_list, rmse_list, label=\"RMSE\", marker='o')\n",
    "    plt.plot(n_factors_list, precision_list, label=f\"Precision@{k}\", marker='o')\n",
    "    plt.plot(n_factors_list, recall_list, label=f\"Recall@{k}\", marker='o')\n",
    "    plt.xlabel(\"n_factors\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"SVD Performance Metrics vs. n_factors\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Bestes Ergebnis\n",
    "    best_idx = np.argmin(rmse_list)\n",
    "    best_n_factors = n_factors_list[best_idx]\n",
    "    print(f\"\\nOptimaler n_factors: {best_n_factors}\")\n",
    "    print(f\"Beste RMSE: {rmse_list[best_idx]:.4f}\")\n",
    "    print(f\"Precision@{k}: {precision_list[best_idx]:.4f}\")\n",
    "    print(f\"Recall@{k}: {recall_list[best_idx]:.4f}\")\n",
    "\n",
    "# Beispiel-Aufruf:\n",
    "n_factors_range = np.linspace(1, 100, 100, dtype=int)\n",
    "optimize_n_factors(ratings, n_factors_range, k=10)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_factors=1 | RMSE=0.8760 | Precision@10=0.7301 | Recall@10=0.5084\n",
      "n_factors=2 | RMSE=0.8766 | Precision@10=0.7308 | Recall@10=0.5086\n",
      "n_factors=3 | RMSE=0.8765 | Precision@10=0.7303 | Recall@10=0.5095\n",
      "n_factors=4 | RMSE=0.8763 | Precision@10=0.7331 | Recall@10=0.5073\n",
      "n_factors=5 | RMSE=0.8764 | Precision@10=0.7329 | Recall@10=0.5130\n",
      "n_factors=6 | RMSE=0.8763 | Precision@10=0.7327 | Recall@10=0.5089\n",
      "n_factors=7 | RMSE=0.8753 | Precision@10=0.7301 | Recall@10=0.5072\n",
      "n_factors=8 | RMSE=0.8762 | Precision@10=0.7371 | Recall@10=0.5097\n",
      "n_factors=9 | RMSE=0.8776 | Precision@10=0.7294 | Recall@10=0.5072\n",
      "n_factors=10 | RMSE=0.8754 | Precision@10=0.7270 | Recall@10=0.5103\n",
      "n_factors=11 | RMSE=0.8773 | Precision@10=0.7344 | Recall@10=0.5108\n",
      "n_factors=12 | RMSE=0.8750 | Precision@10=0.7367 | Recall@10=0.5065\n",
      "n_factors=13 | RMSE=0.8760 | Precision@10=0.7306 | Recall@10=0.5056\n",
      "n_factors=14 | RMSE=0.8742 | Precision@10=0.7353 | Recall@10=0.5098\n",
      "n_factors=15 | RMSE=0.8764 | Precision@10=0.7378 | Recall@10=0.5096\n",
      "n_factors=16 | RMSE=0.8769 | Precision@10=0.7296 | Recall@10=0.5066\n",
      "n_factors=17 | RMSE=0.8771 | Precision@10=0.7433 | Recall@10=0.5108\n",
      "n_factors=18 | RMSE=0.8773 | Precision@10=0.7310 | Recall@10=0.5091\n",
      "n_factors=19 | RMSE=0.8745 | Precision@10=0.7368 | Recall@10=0.5074\n",
      "n_factors=20 | RMSE=0.8777 | Precision@10=0.7377 | Recall@10=0.5117\n",
      "n_factors=21 | RMSE=0.8769 | Precision@10=0.7341 | Recall@10=0.5073\n",
      "n_factors=22 | RMSE=0.8760 | Precision@10=0.7402 | Recall@10=0.5109\n",
      "n_factors=23 | RMSE=0.8761 | Precision@10=0.7333 | Recall@10=0.5078\n",
      "n_factors=24 | RMSE=0.8794 | Precision@10=0.7334 | Recall@10=0.5071\n",
      "n_factors=25 | RMSE=0.8785 | Precision@10=0.7331 | Recall@10=0.5064\n",
      "n_factors=26 | RMSE=0.8767 | Precision@10=0.7381 | Recall@10=0.5097\n",
      "n_factors=27 | RMSE=0.8761 | Precision@10=0.7356 | Recall@10=0.5081\n",
      "n_factors=28 | RMSE=0.8759 | Precision@10=0.7373 | Recall@10=0.5089\n",
      "n_factors=29 | RMSE=0.8764 | Precision@10=0.7324 | Recall@10=0.5068\n",
      "n_factors=30 | RMSE=0.8785 | Precision@10=0.7365 | Recall@10=0.5115\n",
      "n_factors=31 | RMSE=0.8773 | Precision@10=0.7396 | Recall@10=0.5114\n",
      "n_factors=32 | RMSE=0.8781 | Precision@10=0.7424 | Recall@10=0.5077\n",
      "n_factors=33 | RMSE=0.8774 | Precision@10=0.7433 | Recall@10=0.5154\n",
      "n_factors=34 | RMSE=0.8797 | Precision@10=0.7371 | Recall@10=0.5084\n",
      "n_factors=35 | RMSE=0.8781 | Precision@10=0.7418 | Recall@10=0.5073\n",
      "n_factors=36 | RMSE=0.8789 | Precision@10=0.7315 | Recall@10=0.5048\n",
      "n_factors=37 | RMSE=0.8779 | Precision@10=0.7357 | Recall@10=0.5139\n",
      "n_factors=38 | RMSE=0.8764 | Precision@10=0.7454 | Recall@10=0.5161\n",
      "n_factors=39 | RMSE=0.8750 | Precision@10=0.7432 | Recall@10=0.5068\n",
      "n_factors=40 | RMSE=0.8780 | Precision@10=0.7439 | Recall@10=0.5145\n",
      "n_factors=41 | RMSE=0.8781 | Precision@10=0.7429 | Recall@10=0.5155\n",
      "n_factors=42 | RMSE=0.8769 | Precision@10=0.7295 | Recall@10=0.5051\n",
      "n_factors=43 | RMSE=0.8777 | Precision@10=0.7369 | Recall@10=0.5099\n",
      "n_factors=44 | RMSE=0.8797 | Precision@10=0.7420 | Recall@10=0.5088\n",
      "n_factors=45 | RMSE=0.8773 | Precision@10=0.7337 | Recall@10=0.5061\n",
      "n_factors=46 | RMSE=0.8774 | Precision@10=0.7451 | Recall@10=0.5119\n",
      "n_factors=47 | RMSE=0.8765 | Precision@10=0.7401 | Recall@10=0.5132\n",
      "n_factors=48 | RMSE=0.8778 | Precision@10=0.7427 | Recall@10=0.5145\n",
      "n_factors=49 | RMSE=0.8800 | Precision@10=0.7470 | Recall@10=0.5175\n",
      "n_factors=50 | RMSE=0.8766 | Precision@10=0.7406 | Recall@10=0.5148\n",
      "n_factors=51 | RMSE=0.8789 | Precision@10=0.7348 | Recall@10=0.5091\n",
      "n_factors=52 | RMSE=0.8809 | Precision@10=0.7365 | Recall@10=0.5057\n",
      "n_factors=53 | RMSE=0.8790 | Precision@10=0.7444 | Recall@10=0.5116\n",
      "n_factors=54 | RMSE=0.8804 | Precision@10=0.7327 | Recall@10=0.5079\n",
      "n_factors=55 | RMSE=0.8779 | Precision@10=0.7405 | Recall@10=0.5056\n",
      "n_factors=56 | RMSE=0.8799 | Precision@10=0.7382 | Recall@10=0.5087\n",
      "n_factors=57 | RMSE=0.8795 | Precision@10=0.7410 | Recall@10=0.5099\n",
      "n_factors=58 | RMSE=0.8776 | Precision@10=0.7436 | Recall@10=0.5120\n",
      "n_factors=59 | RMSE=0.8800 | Precision@10=0.7362 | Recall@10=0.5099\n",
      "n_factors=60 | RMSE=0.8770 | Precision@10=0.7483 | Recall@10=0.5197\n",
      "n_factors=61 | RMSE=0.8795 | Precision@10=0.7373 | Recall@10=0.5105\n",
      "n_factors=62 | RMSE=0.8779 | Precision@10=0.7472 | Recall@10=0.5137\n",
      "n_factors=63 | RMSE=0.8800 | Precision@10=0.7406 | Recall@10=0.5062\n",
      "n_factors=64 | RMSE=0.8796 | Precision@10=0.7357 | Recall@10=0.5058\n",
      "n_factors=65 | RMSE=0.8760 | Precision@10=0.7460 | Recall@10=0.5145\n",
      "n_factors=66 | RMSE=0.8772 | Precision@10=0.7522 | Recall@10=0.5167\n",
      "n_factors=67 | RMSE=0.8789 | Precision@10=0.7513 | Recall@10=0.5136\n",
      "n_factors=68 | RMSE=0.8779 | Precision@10=0.7397 | Recall@10=0.5082\n",
      "n_factors=69 | RMSE=0.8778 | Precision@10=0.7409 | Recall@10=0.5091\n",
      "n_factors=70 | RMSE=0.8796 | Precision@10=0.7470 | Recall@10=0.5065\n",
      "n_factors=71 | RMSE=0.8773 | Precision@10=0.7358 | Recall@10=0.5140\n",
      "n_factors=72 | RMSE=0.8790 | Precision@10=0.7404 | Recall@10=0.5078\n",
      "n_factors=73 | RMSE=0.8793 | Precision@10=0.7385 | Recall@10=0.5084\n",
      "n_factors=74 | RMSE=0.8803 | Precision@10=0.7460 | Recall@10=0.5129\n",
      "n_factors=75 | RMSE=0.8788 | Precision@10=0.7432 | Recall@10=0.5131\n",
      "n_factors=76 | RMSE=0.8798 | Precision@10=0.7384 | Recall@10=0.5109\n",
      "n_factors=77 | RMSE=0.8785 | Precision@10=0.7343 | Recall@10=0.5058\n",
      "n_factors=78 | RMSE=0.8801 | Precision@10=0.7388 | Recall@10=0.5140\n",
      "n_factors=79 | RMSE=0.8807 | Precision@10=0.7447 | Recall@10=0.5147\n",
      "n_factors=80 | RMSE=0.8777 | Precision@10=0.7475 | Recall@10=0.5155\n",
      "n_factors=81 | RMSE=0.8796 | Precision@10=0.7371 | Recall@10=0.5099\n",
      "n_factors=82 | RMSE=0.8778 | Precision@10=0.7413 | Recall@10=0.5127\n",
      "n_factors=83 | RMSE=0.8809 | Precision@10=0.7394 | Recall@10=0.5090\n",
      "n_factors=84 | RMSE=0.8803 | Precision@10=0.7489 | Recall@10=0.5108\n",
      "n_factors=85 | RMSE=0.8815 | Precision@10=0.7410 | Recall@10=0.5138\n",
      "n_factors=86 | RMSE=0.8807 | Precision@10=0.7398 | Recall@10=0.5135\n",
      "n_factors=87 | RMSE=0.8799 | Precision@10=0.7445 | Recall@10=0.5142\n",
      "n_factors=88 | RMSE=0.8786 | Precision@10=0.7409 | Recall@10=0.5081\n",
      "n_factors=89 | RMSE=0.8808 | Precision@10=0.7395 | Recall@10=0.5082\n",
      "n_factors=90 | RMSE=0.8821 | Precision@10=0.7287 | Recall@10=0.5038\n",
      "n_factors=91 | RMSE=0.8797 | Precision@10=0.7433 | Recall@10=0.5106\n",
      "n_factors=92 | RMSE=0.8802 | Precision@10=0.7453 | Recall@10=0.5175\n",
      "n_factors=93 | RMSE=0.8801 | Precision@10=0.7458 | Recall@10=0.5078\n",
      "n_factors=94 | RMSE=0.8787 | Precision@10=0.7458 | Recall@10=0.5171\n",
      "n_factors=95 | RMSE=0.8814 | Precision@10=0.7361 | Recall@10=0.5099\n",
      "n_factors=96 | RMSE=0.8809 | Precision@10=0.7384 | Recall@10=0.5058\n",
      "n_factors=97 | RMSE=0.8805 | Precision@10=0.7453 | Recall@10=0.5138\n",
      "n_factors=98 | RMSE=0.8802 | Precision@10=0.7414 | Recall@10=0.5090\n",
      "n_factors=99 | RMSE=0.8806 | Precision@10=0.7454 | Recall@10=0.5096\n",
      "n_factors=100 | RMSE=0.8817 | Precision@10=0.7392 | Recall@10=0.5051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimaler n_factors: 14\n",
      "Beste RMSE: 0.8742\n",
      "Precision@10: 0.7353\n",
      "Recall@10: 0.5098\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9 - Everything goes (30 points)\n",
    "In this exercise you can explore different methods of RS. You are not limited what methods you apply. You can try to improve the methods from the earlier exercises by modifiying them or generating ensemble or hybrid RS. Also you could train deep neural networks, use NLP methods, use the available links to imdb available in the dataset to further enrich the dataset or find an obscure method by someone else on Github. \n",
    "Document what your inspirations and sources are and describe the method conceptually. \n",
    "\n",
    "**Build and optimize in total *three* different methods. The last one has the additional requirement that it should increase the diversity of the recommendations in order to minimize filter bubbles.**\n",
    "\n",
    "**Important: If you use the work of someone else you must be able to explain the method conceptually during the defense MSP.** \n",
    "\n",
    "Output the performance metrics of exercise 3. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10 - Compare all RS that you build in this challenge (8 points)\n",
    "a) Compile a table with the performance metrics of exercise 3 for all RS from this MC (Make sure to include the baseline RS and random RS) on the test set defined in exercise 3. Also generate comparative plots. Discuss.\n",
    "\n",
    "b) Why is it important to keep a test set seperate till the end of a benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the Guidelines for Implementation and Submission one more time.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RSY_FS24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
